{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3c81dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e22a6a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init params:\n",
      "test_name: test_cifar_pref\n",
      "dataset_name: cifar10\n",
      "num_clients: 5\n",
      "num_classes: 10\n",
      "distribution_type: preferential_class\n",
      "model_name: resnet18\n",
      "loss_name: cross_entropy\n",
      "trainer_name: sgd\n",
      "train_epochs: 40\n",
      "target_client: 0\n",
      "num_tests: 20\n"
     ]
    }
   ],
   "source": [
    "stat_test_name = \"test_cifar_pref\"\n",
    "\n",
    "stat_tests_path = \"stat_tests\" \n",
    "stat_test_path = os.path.join(stat_tests_path, stat_test_name)\n",
    "if not os.path.exists(stat_test_path):\n",
    "    raise FileNotFoundError(f\"Stat test path {stat_test_path} does not exist.\")\n",
    "\n",
    "init_params_path = os.path.join(stat_test_path, \"init_params.pkl\")\n",
    "test_params_path = os.path.join(stat_test_path, \"test_params.pkl\")\n",
    "\n",
    "with open(init_params_path, \"rb\") as f:\n",
    "    init_params = pickle.load(f)\n",
    "with open(test_params_path, \"rb\") as f:\n",
    "    test_params = pickle.load(f)\n",
    "\n",
    "\n",
    "print(\"Init params:\")\n",
    "for k, v in init_params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "num_tests = init_params[\"num_tests\"] \n",
    "num_tests = 10\n",
    "\n",
    "tests_results = []  # 2-dim list [idx of repeated test][idx of test]\n",
    "for i in range(num_tests):\n",
    "    test_path = os.path.join(stat_test_path, f\"test_{i}\")\n",
    "    test_result_path = os.path.join(test_path, \"test_results.pkl\")\n",
    "    \n",
    "    with open(test_result_path, \"rb\") as f:\n",
    "\n",
    "        test_result = pickle.load(f)\n",
    "    tests_results.append(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be64322b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target from classes\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for i in range(num_tests):\n",
    "        for j in range(len(tests_results[i])):\n",
    "            tests_results[i][j]['trained_target_accuracy'] = tests_results[i][j]['trained_clients_accuracies'][init_params['target_client']]\n",
    "            tests_results[i][j]['benchmark_target_accuracy'] = tests_results[i][j]['benchmark_clients_accuracies'][init_params['target_client']]\n",
    "            tests_results[i][j]['reset_target_accuracy'] = tests_results[i][j]['reset_clients_accuracies'][init_params['target_client']]\n",
    "            tests_results[i][j]['retrained_target_accuracy'] = tests_results[i][j]['retrained_clients_accuracies'][init_params['target_client']]\n",
    "    \n",
    "    print(\"Target from clients\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    for i in range(num_tests):\n",
    "        for j in range(len(tests_results[i])):\n",
    "            tests_results[i][j]['trained_target_accuracy'] = tests_results[i][j]['trained_class_accuracies'][init_params['target_client']+init_params['num_clients']]\n",
    "            tests_results[i][j]['benchmark_target_accuracy'] = tests_results[i][j]['benchmark_class_accuracies'][init_params['target_client']+init_params['num_clients']]\n",
    "            tests_results[i][j]['reset_target_accuracy'] = tests_results[i][j]['reset_class_accuracies'][init_params['target_client']+init_params['num_clients']]\n",
    "            tests_results[i][j]['retrained_target_accuracy'] = tests_results[i][j]['retrained_class_accuracies'][init_params['target_client']+init_params['num_clients']]\n",
    "    \n",
    "    print(\"Target from classes\")\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88b82ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtest params:\n",
      "subtest: 1\n",
      "unlearning_method: parameters\n",
      "tests: ['test_accuracy', 'class_accuracies', 'mia']\n",
      "mia_classifier_types: ['nn', 'logistic']\n",
      "retrain_epochs: 1\n",
      "\n",
      "Available results:\n",
      "total_individual_reset_params\n",
      "trained_test_accuracy\n",
      "benchmark_test_accuracy\n",
      "reset_test_accuracy\n",
      "retrained_test_accuracy\n",
      "trained_class_accuracies\n",
      "benchmark_class_accuracies\n",
      "reset_class_accuracies\n",
      "retrained_class_accuracies\n",
      "trained_mia_nn\n",
      "benchmark_mia_nn\n",
      "reset_mia_nn\n",
      "retrained_mia_nn\n",
      "trained_mia_logistic\n",
      "benchmark_mia_logistic\n",
      "reset_mia_logistic\n",
      "retrained_mia_logistic\n",
      "trained_target_accuracy\n",
      "benchmark_target_accuracy\n",
      "reset_target_accuracy\n",
      "retrained_target_accuracy\n",
      "\n",
      "Unlearning percentages: [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75]\n"
     ]
    }
   ],
   "source": [
    "subtest = 1\n",
    "\n",
    "subtest_params = []\n",
    "subtest_results = []    # 2-dim list [idx of test][idx of repeated test]\n",
    "for i, test_param in enumerate(test_params):\n",
    "    if test_param[\"subtest\"] == subtest:\n",
    "        subtest_params.append(test_param)\n",
    "        subtest_results.append([])\n",
    "        for j in range(num_tests):\n",
    "            subtest_results[-1].append(tests_results[j][i])\n",
    "\n",
    "print(\"Subtest params:\")\n",
    "for key, value in subtest_params[0].items():\n",
    "    if key == \"unlearning_percentage\":\n",
    "        continue\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nAvailable results:\")\n",
    "for key in subtest_results[0][0].keys():\n",
    "    print(key)\n",
    "\n",
    "percentages = []\n",
    "for test_param in subtest_params:\n",
    "    percentages.append(int(test_param[\"unlearning_percentage\"]))\n",
    "\n",
    "print(f\"\\nUnlearning percentages: {percentages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0bfe3e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Results for test\\_cifar\\_pref with unlearning percentage 40\\%}\n",
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "Model & Target accuracy & MIA (logistic) & Test accuracy \\\\\n",
      "\\midrule\n",
      "trained & 68.28 ± 4.04 & 65.52 ± 1.89 & 79.75 ± 0.52 \\\\\n",
      "benchmark & 0.00 ± 0.00 & 71.98 ± 1.25 & 73.41 ± 0.36 \\\\\n",
      "reset & 0.00 ± 0.00 & 55.77 ± 7.02 & 10.91 ± 1.36 \\\\\n",
      "retrained & 0.00 ± 0.00 & 70.94 ± 0.49 & 70.24 ± 0.38 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percentage = 40\n",
    "\n",
    "mia_method = \"logistic\"\n",
    "\n",
    "selected_idx = percentages.index(percentage)\n",
    "selected_results = subtest_results[selected_idx]\n",
    "\n",
    "data= { 'Model': ['trained', 'benchmark', 'reset', 'retrained'],\n",
    "        'Target accuracy': [],\n",
    "        'MIA': [],\n",
    "        'Test accuracy': []\n",
    "        }\n",
    "\n",
    "for model in data[\"Model\"]:\n",
    "    target_accuracies = [result[f'{model}_target_accuracy'] for result in selected_results]\n",
    "    test_accuracies = [result[f'{model}_test_accuracy'] for result in selected_results]\n",
    "    mia_aucs = [result[f'{model}_mia_{mia_method}']['roc_auc'] for result in selected_results]\n",
    "    target_avg = np.mean(target_accuracies)*100\n",
    "    target_std = np.std(target_accuracies)*100\n",
    "    test_avg = np.mean(test_accuracies)*100\n",
    "    test_std = np.std(test_accuracies)*100\n",
    "    mia_avg = np.mean(mia_aucs)*100\n",
    "    mia_std = np.std(mia_aucs)*100\n",
    "\n",
    "    data[\"Target accuracy\"].append(f\"{target_avg:.2f} ± {target_std:.2f}\")\n",
    "    data[\"MIA\"].append(f\"{mia_avg:.2f} ± {mia_std:.2f}\")\n",
    "    data[\"Test accuracy\"].append(f\"{test_avg:.2f} ± {test_std:.2f}\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.rename(columns={\"MIA\": f\"MIA ({mia_method})\"})\n",
    "caption = f\"Results for {stat_test_name} with unlearning percentage {percentage}%\"\n",
    "tex_escape = {\n",
    "    '&':  '\\&',\n",
    "    '%':  '\\%', \n",
    "    '$':  '\\$', \n",
    "    '#':  '\\#', \n",
    "    '_':  '\\_', \n",
    "    '^':  '\\^', \n",
    "}\n",
    "for key, value in tex_escape.items():\n",
    "    caption = caption.replace(key, value)\n",
    "latex_table = df.to_latex(index=False, escape=False, caption=caption)\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed-learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
