{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "QKyTAuEodw7x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from backpack import backpack, extend\n",
        "from backpack.extensions import DiagHessian\n",
        "import copy\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "8ntXU7nFdw70"
      },
      "outputs": [],
      "source": [
        "# Create base images (happy, sad, neutral faces)\n",
        "def create_base_images():\n",
        "    base_images = np.zeros((3, 16, 16))\n",
        "    # Happy face (index 0)\n",
        "    base_images[0, 4, 4] = base_images[0, 4, 11] = 1  # Eyes\n",
        "    base_images[0, 10, 5:11] = 1  # Smile (curved upwards)\n",
        "    base_images[0, 11, 4] = base_images[0, 11, 11] = 1  # Smile curve corners\n",
        "    base_images[0, 12, 3] = base_images[0, 12, 12] = 1  # Smile curve corners\n",
        "    \n",
        "    # Sad face (index 1)\n",
        "    base_images[1, 4, 4] = base_images[1, 4, 11] = 1  # Eyes\n",
        "    base_images[1, 11, 5:11] = 1  # Frown (curved downwards)\n",
        "    base_images[1, 10, 4] = base_images[1, 10, 11] = 1  # Smile curve corners\n",
        "    base_images[1, 9, 3] = base_images[1, 9, 12] = 1  # Smile curve corners\n",
        "\n",
        "    # Neutral face (index 2)\n",
        "    base_images[2, 4, 4] = base_images[2, 4, 11] = 1  # Eyes\n",
        "    base_images[2, 10, 4:12] = 1  # Straight line for mouth\n",
        "    \n",
        "    return base_images\n",
        "\n",
        "# Generate noisy dataset\n",
        "def generate_dataset(base_images, label=-1, num_samples=3000, noise_level=0.2, dev='cpu'):\n",
        "    images = []\n",
        "    labels = []\n",
        "    in_label=label\n",
        "    for i in range(num_samples):\n",
        "        if in_label == -1:\n",
        "            label = np.random.randint(0, 3)\n",
        "        img = base_images[label] + noise_level * np.random.randn(16, 16)\n",
        "        img = np.clip(img, 0, 1)  # Keep pixel values between 0 and 1\n",
        "        images.append(img)\n",
        "        labels.append(label)\n",
        "    return torch.tensor(images, dtype=torch.float32, device=dev).unsqueeze(1), torch.tensor(labels, dtype=torch.long,device=dev)\n",
        "\n",
        "# Define simple CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(16 * 16 * 16, 64)\n",
        "        self.fc2 = nn.Linear(64, 3)  # 3 classes\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "    \n",
        "# Compute Hessian\n",
        "def compute_hessian(model, criterion, data, target):\n",
        "    model.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "    grad_params = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
        "    hessian = []\n",
        "    for grad in grad_params:\n",
        "        grad_vector = grad.view(-1)\n",
        "        row = []\n",
        "        for g in grad_vector:\n",
        "            second_derivative = torch.autograd.grad(g, model.parameters(), retain_graph=True)\n",
        "            row.append(torch.cat([sd.contiguous().view(-1) for sd in second_derivative]))\n",
        "        hessian.append(torch.stack(row))\n",
        "    return torch.cat(hessian, dim=0)\n",
        "\n",
        "# Training function\n",
        "def train(model, train_loader, criterion, optimizer, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "BFtPUviudw71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/7], Loss: 0.0046\n",
            "Epoch [2/7], Loss: 0.0005\n",
            "Epoch [3/7], Loss: 0.0002\n",
            "Epoch [4/7], Loss: 0.0001\n",
            "Epoch [5/7], Loss: 0.0001\n",
            "Epoch [6/7], Loss: 0.0000\n",
            "Epoch [7/7], Loss: 0.0000\n",
            "Epoch [1/7], Loss: 0.0138\n",
            "Epoch [2/7], Loss: 0.0013\n",
            "Epoch [3/7], Loss: 0.0007\n",
            "Epoch [4/7], Loss: 0.0004\n",
            "Epoch [5/7], Loss: 0.0002\n",
            "Epoch [6/7], Loss: 0.0002\n",
            "Epoch [7/7], Loss: 0.0001\n"
          ]
        }
      ],
      "source": [
        "# Main execution\n",
        "device='cuda'\n",
        "\n",
        "base_images = create_base_images()\n",
        "n_samples = 3000\n",
        "images_h, labels_h = generate_dataset(base_images, label=0, num_samples=n_samples//3,dev=device)\n",
        "images_s, labels_s = generate_dataset(base_images, label=1, num_samples=n_samples//3,dev=device)\n",
        "images_n, labels_n = generate_dataset(base_images, label=2, num_samples=n_samples//3,dev=device)\n",
        "train_dataset_h = TensorDataset(images_h, labels_h)\n",
        "train_dataset_s = TensorDataset(images_s, labels_s)\n",
        "train_dataset_n = TensorDataset(images_n, labels_n)\n",
        "\n",
        "train_dataset = train_dataset_h + train_dataset_s + train_dataset_n\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "train_dataset_unp = train_dataset_h + train_dataset_n\n",
        "train_loader_unp = DataLoader(train_dataset_unp, batch_size=32, shuffle=True)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 8, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Flatten(),                    # Flatten the 16x16x16 feature map\n",
        "    nn.Linear(16 * 16 * 16, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 3)                 # 3 classes\n",
        ")\n",
        "\n",
        "model = extend(model)\n",
        "model_unp = copy.deepcopy(model)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion_unp = nn.CrossEntropyLoss()\n",
        "lossfunc = extend(criterion)\n",
        "lossfunc_unp = extend(criterion_unp)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "optimizer_unp = optim.Adam(model_unp.parameters(), lr=0.001)\n",
        "\n",
        "model = model.to(device)\n",
        "train(model, train_loader, criterion, optimizer, epochs=7)\n",
        "\n",
        "model_unp = model_unp.to(device)\n",
        "train(model_unp, train_loader_unp, criterion_unp, optimizer_unp, epochs=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "MH6Gpu5tdw72"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATYAAABpCAYAAACwEw8/AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAhxJREFUeJzt3UFOwzAUQMEGcf8rhz00KIg2tl9mloiFjcWT1V/J277v+wMg5GP0AgBeTdiAHGEDcoQNyBE2IEfYgBxhA3KEDcj5PPuL27a9cx239YrvRzub9/jv2TiX9zhzLm5sQI6wATnCBuQIG5AjbECOsAE5wgbkCBuQI2xAjrABOcIG5AgbkCNsQI6wATnCBuQIG5AjbECOsAE5wgbkCBuQc/oxl3c4epRh9CMYz9Y1ek1XczZzci7nuLEBOcIG5AgbkCNsQI6wATlDp6KjJzlHZl3XlWb9G8y6rqvMuv/Z1uXGBuQIG5AjbECOsAE5wgbkCBuQI2xAjrABOcIG5AgbkCNsQI6wATnCBuQIG5AjbECOsAE5wgbkCBuQI2xAjrABOUMfc2EO+77/+Nlsj3P85tn6H4+19sBrubEBOcIG5AgbkCNsQI6wATlTTkWPplxXuds07dl+Z500rj7B/a/R/xt/MfJc3NiAHGEDcoQNyBE2IGfo8MAH1PM62u/oD6/vdg7f3X3/Z7mxATnCBuQIG5AjbEDOZcODlT6QX+mb+Fe7235ZkxsbkCNsQI6wATnCBuQIG5Bz2VR09Wna6uuHO3FjA3KEDcgRNiBH2IAcYQNyhA3IETYgR9iAHGEDcoQNyBE2IEfYgBxhA3KEDcgRNiBn24+eXwJYlBsbkCNsQI6wATnCBuQIG5AjbECOsAE5wgbkCBuQ8wX14kUAzra3YAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Test model on some samples\n",
        "test_samples_h, _ = generate_dataset(base_images, label=0, num_samples=3, dev=device)\n",
        "test_samples_s, _ = generate_dataset(base_images, label=1, num_samples=3, dev=device)\n",
        "test_samples_n, _ = generate_dataset(base_images, label=2, num_samples=3, dev=device)\n",
        "test_samples = torch.cat((test_samples_h, test_samples_s, test_samples_n), dim=0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    predictions = model(test_samples).argmax(dim=1)\n",
        "\n",
        "# Show some test images\n",
        "for i in range(3):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(base_images[i].squeeze(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "test_samples = test_samples.cpu()\n",
        "# Show some test images\n",
        "for i in range(3):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(test_samples[i].squeeze(), cmap='gray')\n",
        "    plt.title(f'Pred: {predictions[i].item()}')\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "for i in range(3):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(test_samples[3+i].squeeze(), cmap='gray')\n",
        "    plt.title(f'Pred: {predictions[3+i].item()}')\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "for i in range(3):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(test_samples[6+i].squeeze(), cmap='gray')\n",
        "    plt.title(f'Pred: {predictions[6+i].item()}')\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 3000, Poisoned samples: 1000\n",
            "Computing influence of poisoned samples...\n",
            "Removed 0% (0) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 1% (10) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 2% (20) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 3% (30) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 4% (40) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 5% (50) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 6% (60) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 7% (70) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 8% (80) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 9% (90) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 10% (100) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 11% (110) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 12% (120) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 13% (130) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 14% (140) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 15% (150) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 16% (160) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 17% (170) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 18% (180) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 19% (190) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 20% (200) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 21% (210) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 22% (220) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 23% (230) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 24% (240) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 25% (250) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 26% (260) poisoned samples: Gradient norm = 0.0011, Loss = 0.0000\n",
            "Removed 27% (270) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 28% (280) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 29% (290) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 30% (300) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 31% (310) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 32% (320) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 33% (330) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 34% (340) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 35% (350) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 36% (360) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 37% (370) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 38% (380) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 39% (390) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 40% (400) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 41% (410) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 42% (420) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 43% (430) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 44% (440) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 45% (450) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 46% (460) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 47% (470) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 48% (480) poisoned samples: Gradient norm = 0.0012, Loss = 0.0000\n",
            "Removed 49% (490) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 50% (500) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 51% (510) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 52% (520) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 53% (530) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 54% (540) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 55% (550) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 56% (560) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 57% (570) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 58% (580) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 59% (590) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 60% (600) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 61% (610) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 62% (620) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 63% (630) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 64% (640) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 65% (650) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 66% (660) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 67% (670) poisoned samples: Gradient norm = 0.0013, Loss = 0.0000\n",
            "Removed 68% (680) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 69% (690) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 70% (700) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 71% (710) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 72% (720) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 73% (730) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 74% (740) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 75% (750) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 76% (760) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 77% (770) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 78% (780) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 79% (790) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 80% (800) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 81% (810) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 82% (820) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 83% (830) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 84% (840) poisoned samples: Gradient norm = 0.0014, Loss = 0.0000\n",
            "Removed 85% (850) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 86% (860) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 87% (870) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 88% (880) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 89% (890) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 90% (900) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 91% (910) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 92% (920) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 93% (930) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 94% (940) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 95% (950) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 96% (960) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 97% (970) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 98% (980) poisoned samples: Gradient norm = 0.0015, Loss = 0.0000\n",
            "Removed 99% (990) poisoned samples: Gradient norm = 0.0016, Loss = 0.0000\n",
            "Removed 100% (1000) poisoned samples: Gradient norm = 0.0016, Loss = 0.0000\n",
            "\n",
            "Significant gradient change detected at 4% removal\n",
            "This corresponds to removing 40 poisoned samples\n",
            "Gradient norm increased by 0.0000\n"
          ]
        }
      ],
      "source": [
        "def compute_loss_gradient_after_removal(model, criterion, images, labels, indices_to_remove):\n",
        "    \"\"\"\n",
        "    Compute the gradient of the loss function after removing specific samples.\n",
        "\n",
        "    Args:\n",
        "        model: The trained model\n",
        "        criterion: Loss function\n",
        "        images: All training images\n",
        "        labels: All training labels\n",
        "        indices_to_remove: Indices of samples to exclude from gradient computation\n",
        "\n",
        "    Returns:\n",
        "        Gradient norm of the loss function on the reduced dataset\n",
        "    \"\"\"\n",
        "    # Create mask for samples to keep\n",
        "    mask = torch.ones(len(images), dtype=torch.bool)\n",
        "    mask[indices_to_remove] = False\n",
        "\n",
        "    # Get remaining samples\n",
        "    remaining_images = images[mask]\n",
        "    remaining_labels = labels[mask]\n",
        "\n",
        "    # Compute gradient on remaining samples\n",
        "    model.zero_grad()\n",
        "    outputs = model(remaining_images)\n",
        "    loss = criterion(outputs, remaining_labels)\n",
        "    loss.backward()\n",
        "\n",
        "    # Calculate gradient norm\n",
        "    grad_norm = 0\n",
        "    for param in model.parameters():\n",
        "        if param.grad is not None:\n",
        "            grad_norm += torch.norm(param.grad).item()\n",
        "\n",
        "    return grad_norm, loss.item()\n",
        "\n",
        "def find_gradient_threshold_for_stability(model, criterion, images_s, labels_s, images_h, labels_h, images_n, labels_n, add=False):\n",
        "    \"\"\"\n",
        "    Study how many poisoned samples can be removed while maintaining a gradient below threshold.\n",
        "\n",
        "    Args:\n",
        "        model: The trained model\n",
        "        criterion: Loss function\n",
        "        images_s, labels_s: Poisoned samples (sad faces)\n",
        "        images_h, labels_h: Clean samples (happy faces)\n",
        "        images_n, labels_n: Clean samples (neutral faces)\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with results of the study\n",
        "    \"\"\"\n",
        "    # Combine all datasets for base gradient\n",
        "    all_images = torch.cat([images_h, images_s, images_n])\n",
        "    all_labels = torch.cat([labels_h, labels_s, labels_n])\n",
        "\n",
        "    # Create indices for poisoned samples in the combined dataset\n",
        "    poison_start_idx = len(images_h)\n",
        "    poison_end_idx = poison_start_idx + len(images_s)\n",
        "    poisoned_indices = list(range(poison_start_idx, poison_end_idx))\n",
        "\n",
        "    print(f\"Total samples: {len(all_images)}, Poisoned samples: {len(poisoned_indices)}\")\n",
        "\n",
        "    # Compute influence of each poisoned sample\n",
        "    print(\"Computing influence of poisoned samples...\")\n",
        "    poisoned_images = images_s\n",
        "    poisoned_labels = labels_s\n",
        "\n",
        "    percentages_to_study = None\n",
        "    # Study gradient changes as we remove more poisoned samples\n",
        "    if add:\n",
        "        percentages_to_study = list(range(100, -1, -1))\n",
        "    else:\n",
        "        percentages_to_study = list(range(0, 101, 1))\n",
        "    results = []\n",
        "    # Get baseline loss and gradient\n",
        "    baseline_grad = baseline_loss = 0\n",
        "\n",
        "    for i, percentage in enumerate(percentages_to_study):\n",
        "\n",
        "        num_to_remove = int(len(poisoned_indices) * percentage / 100)\n",
        "\n",
        "        # Compute gradient after removal\n",
        "        grad_norm, loss = compute_loss_gradient_after_removal(\n",
        "            model, criterion, all_images, all_labels, poisoned_indices[:num_to_remove])\n",
        "        \n",
        "        if i==0:\n",
        "            # Baseline case - no samples removed\n",
        "            baseline_grad = grad_norm\n",
        "            baseline_loss = loss\n",
        "\n",
        "        results.append({\n",
        "            'percentage_removed': percentage,\n",
        "            'num_removed': num_to_remove,\n",
        "            'gradient_norm': grad_norm,\n",
        "            'loss': loss,\n",
        "            'gradient_change': grad_norm - baseline_grad,\n",
        "            'loss_change': loss - baseline_loss\n",
        "        })\n",
        "\n",
        "        print(f\"Removed {percentage}% ({num_to_remove}) poisoned samples: \"f\"Gradient norm = {grad_norm:.4f}, Loss = {loss:.4f}\")\n",
        "\n",
        "    # Convert to DataFrame for easier analysis\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Find the threshold where gradient change becomes significant\n",
        "    significant_change_threshold = 0.01 * baseline_grad  # 5% of baseline gradient norm\n",
        "    max_percentage=0\n",
        "    for result in results:\n",
        "        if abs(result['gradient_change']) > significant_change_threshold:\n",
        "            print(f\"\\nSignificant gradient change detected at {result['percentage_removed']}% removal\")\n",
        "            print(f\"This corresponds to removing {result['num_removed']} poisoned samples\")\n",
        "            print(f\"Gradient norm increased by {result['gradient_change']:.4f}\")\n",
        "            max_percentage=result['percentage_removed']\n",
        "            break\n",
        "    \n",
        "    return results_df, max_percentage\n",
        "\n",
        "# Study gradient thresholds\n",
        "results_df, percetage = find_gradient_threshold_for_stability(\n",
        "    model, criterion, images_s, labels_s, images_h, labels_h, images_n, labels_n\n",
        ")\n",
        "\n",
        "#results_df_unp, percetage_unp = find_gradient_threshold_for_stability(model_unp, criterion_unp, images_s, labels_s, images_h, labels_h, images_n, labels_n, add=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "Eh7FW5W9dw73"
      },
      "outputs": [],
      "source": [
        "def compute_hessians_remove(model, percetage):\n",
        "    unp_num_samples = int(len(images_s) * (100-percetage) / 100)\n",
        "    unp_half_num_samples = int(len(images_s) * (100-percetage/2) / 100)\n",
        "\n",
        "    model.eval()\n",
        "    train_images=torch.cat([images_h,images_s,images_n])\n",
        "    train_labels=torch.cat([labels_h,labels_s,labels_n])\n",
        "    half_images = torch.cat([images_h,images_n,images_s[:unp_half_num_samples]])\n",
        "    half_labels = torch.cat([labels_h,labels_n,labels_s[:unp_half_num_samples]])\n",
        "    all_images = torch.cat([images_h,images_n,images_s[:unp_num_samples]])\n",
        "    all_labels = torch.cat([labels_h,labels_n,labels_s[:unp_num_samples]])\n",
        "\n",
        "    #Compute the Hessian with poisoned dataset\n",
        "    loss = lossfunc(model(train_images), train_labels)\n",
        "\n",
        "    with backpack(DiagHessian()):\n",
        "        loss.backward(retain_graph=True)\n",
        "    hessian = [p.diag_h.clone() for p in model.parameters()]\n",
        "\n",
        "    for p in model.parameters():\n",
        "        if hasattr(p, 'diag_h'):\n",
        "            del p.diag_h\n",
        "\n",
        "\n",
        "    #Compute the Hessian with half poisoned dataset\n",
        "    loss_half = lossfunc(model(half_images), half_labels)\n",
        "\n",
        "    with backpack(DiagHessian()):\n",
        "        loss_half.backward()\n",
        "    hessian_half = [p.diag_h.clone() for p in model.parameters()]\n",
        "\n",
        "    for p in model.parameters():\n",
        "        if hasattr(p, 'diag_h'):\n",
        "            del p.diag_h\n",
        "\n",
        "    #Compute the Hessian with unpoisoned dataset\n",
        "    loss_all = lossfunc(model(all_images), all_labels)\n",
        "\n",
        "    with backpack(DiagHessian()):\n",
        "        loss_all.backward()\n",
        "    hessian_all = [p.diag_h.clone() for p in model.parameters()]\n",
        "\n",
        "    num_removed = len(train_images) - len(all_images)\n",
        "\n",
        "    return hessian,hessian_half,hessian_all,num_removed\n",
        "\n",
        "def compute_hessians_add(model, percetage):\n",
        "    unp_num_samples = int(len(images_s) * (percetage / 100))\n",
        "    unp_half_num_samples = int(len(images_s) * (percetage/2 / 100))\n",
        "\n",
        "    model.eval()\n",
        "    train_images=torch.cat([images_h,images_n])\n",
        "    train_labels=torch.cat([labels_h,labels_n])\n",
        "    half_images = torch.cat([images_h,images_n,images_s[:unp_half_num_samples]])\n",
        "    half_labels = torch.cat([labels_h,labels_n,labels_s[:unp_half_num_samples]])\n",
        "    all_images = torch.cat([images_h,images_n,images_s[:unp_num_samples]])\n",
        "    all_labels = torch.cat([labels_h,labels_n,labels_s[:unp_num_samples]])\n",
        "\n",
        "    #Compute the Hessian with poisoned dataset\n",
        "    loss = lossfunc(model(train_images), train_labels)\n",
        "\n",
        "    with backpack(DiagHessian()):\n",
        "        loss.backward(retain_graph=True)\n",
        "    hessian = [p.diag_h.clone() for p in model.parameters()]\n",
        "\n",
        "    for p in model.parameters():\n",
        "        if hasattr(p, 'diag_h'):\n",
        "            del p.diag_h\n",
        "\n",
        "\n",
        "    #Compute the Hessian with half poisoned dataset\n",
        "    loss_half = lossfunc(model(half_images), half_labels)\n",
        "\n",
        "    with backpack(DiagHessian()):\n",
        "        loss_half.backward()\n",
        "    hessian_half = [p.diag_h.clone() for p in model.parameters()]\n",
        "\n",
        "    for p in model.parameters():\n",
        "        if hasattr(p, 'diag_h'):\n",
        "            del p.diag_h\n",
        "\n",
        "    #Compute the Hessian with unpoisoned dataset\n",
        "    loss_all = lossfunc(model(all_images), all_labels)\n",
        "\n",
        "    with backpack(DiagHessian()):\n",
        "        loss_all.backward()\n",
        "    hessian_all = [p.diag_h.clone() for p in model.parameters()]\n",
        "\n",
        "    num_added = len(all_images) - len(train_images)\n",
        "\n",
        "    return hessian,hessian_half,hessian_all,num_added\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "xJsRQ_Usdw73"
      },
      "outputs": [],
      "source": [
        "def compute_der(tensor1, tensor2):\n",
        "    #Compute first derivative integrals of FI\n",
        "    ratio = tensor1/tensor2\n",
        "    return torch.log(ratio)+ 1/2 * (1-torch.pow(ratio,2))\n",
        "\n",
        "def compute_info(hessian, hessian_half, hessian_unp, num_removed):\n",
        "    print(f\"Removed samples: {num_removed}\")\n",
        "\n",
        "    information = [torch.empty_like(p) for p in hessian]\n",
        "    for i,_ in enumerate(information):\n",
        "        #Compute second derivative integrals of FI\n",
        "        der1 = compute_der(hessian_half[i], hessian[i])\n",
        "        der2 = compute_der(hessian_unp[i], hessian_half[i])\n",
        "        information[i]= torch.nan_to_num(der2-der1)/np.power(num_removed//2,2)\n",
        "\n",
        "    information_quad = [torch.empty_like(p) for p in hessian]\n",
        "    for i,_ in enumerate(information_quad):\n",
        "        ratio = hessian_unp[i]/hessian[i]\n",
        "        A = torch.log(ratio)\n",
        "        B = 1/2 * (1-torch.pow(ratio,2))\n",
        "        information_quad[i]=torch.pow(A,2) + 3/4 * torch.pow(B,2) + A*B\n",
        "        information_quad[i] = torch.nan_to_num(information_quad[i])/np.power(num_removed,2)\n",
        "\n",
        "    #Compute relative differences(just for testing and studying)\n",
        "    delta = [torch.empty_like(p) for p in hessian]\n",
        "    for i,_ in enumerate(delta):\n",
        "        delta[i] = torch.nan_to_num((1/hessian_unp[i]-1/hessian[i])/(1/hessian[i]))\n",
        "\n",
        "    return information, information_quad, delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "g5aXGv-_dw74"
      },
      "outputs": [],
      "source": [
        "def compute_true_info(hessian, hessian_half, hessian_unp, num_removed):\n",
        "    information_true = [torch.empty_like(p) for p in hessian]\n",
        "    A_list = [torch.empty_like(p) for p in hessian]\n",
        "    B_list = [torch.empty_like(p) for p in hessian]\n",
        "    for i,_ in enumerate(A_list):\n",
        "        ratio = torch.where(torch.logical_and(hessian[i]==0, hessian_unp[i]==0), 1, hessian_unp[i]/hessian[i])\n",
        "        A=torch.log(ratio)/num_removed\n",
        "        B=(1/2 * (1-torch.pow(ratio,2)))/num_removed\n",
        "        A[torch.isinf(A)]=0\n",
        "        B[torch.isinf(B)]=0\n",
        "        A_list[i]=torch.nan_to_num(A)\n",
        "        B_list[i]=torch.nan_to_num(B)\n",
        "\n",
        "    A_flat = torch.cat([A.flatten() for A in A_list])\n",
        "    B_flat = torch.cat([B.flatten() for B in B_list])\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    device = torch.device(\"cuda\")\n",
        "    A_flat = A_flat.to(device)\n",
        "    B_flat = B_flat.to(device)\n",
        "    information_true = [torch.empty_like(p).to(device) for p in hessian]\n",
        "    hessian = [p.to(device) for p in hessian]\n",
        "    hessian_unp = [p.to(device) for p in hessian_unp]\n",
        "\n",
        "    information_true_view = [p.view(-1) for p in information_true]\n",
        "    A_list_view = [p.view(-1) for p in A_list]\n",
        "    B_list_view = [p.view(-1) for p in B_list]\n",
        "    num_params = sum([p.numel() for p in hessian])\n",
        "    track=0\n",
        "    print(\"\\nstart\")\n",
        "    for i,_ in enumerate(information_true_view):\n",
        "        for j,_ in enumerate(information_true_view[i]):\n",
        "            if (track+j)%(num_params//10)==0:\n",
        "                print((track+j)//(num_params//100))\n",
        "\n",
        "            temp=A_list_view[i][j]*A_flat + B_list_view[i][j]*B_flat + A_list_view[i][j]*B_flat + B_list_view[i][j]*A_flat\n",
        "            information_true_view[i][j] = torch.sum(temp)+2*torch.pow(B_list_view[i][j],2)\n",
        "        track+=information_true[i].numel()\n",
        "\n",
        "    return information_true\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "6tTD-YMzdw76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed samples: 40\n",
            "Removed samples: 40\n",
            "\n",
            "start\n",
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "info,info_quad,delt = compute_info(*compute_hessians_remove(model, percetage))\n",
        "info_unp,info_quad_unp,delt_unp = compute_info(*compute_hessians_add(model_unp, percetage))\n",
        "\n",
        "info_true = compute_true_info(*compute_hessians_remove(model, percetage))\n",
        "#info_true_unp = compute_true_info(*compute_hessians_add(model_unp, percetage))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "jKO49_ivdw77"
      },
      "outputs": [],
      "source": [
        "# 1. Sum all values in the information dictionary\n",
        "def sum_information_values(information):\n",
        "    # Initialize an empty list to store all flattened tensors\n",
        "    all_values = []\n",
        "\n",
        "    # Iterate through each parameter's information tensor\n",
        "    for tensor in information:\n",
        "        # Flatten the tensor and add to our list\n",
        "        temp=torch.nan_to_num(tensor.flatten())\n",
        "        temp = temp[torch.isinf(temp)==0]\n",
        "        temp = temp[temp!=0]\n",
        "        all_values.append(temp)\n",
        "\n",
        "    # Concatenate all tensors into one large tensor\n",
        "    combined_tensor = torch.cat(all_values)\n",
        "    print(len(combined_tensor))\n",
        "    return combined_tensor\n",
        "\n",
        "# 2. Plot the summed information\n",
        "def plot_information(information):\n",
        "    combined_tensor = sum_information_values(information)\n",
        "\n",
        "    # Convert to numpy for plotting\n",
        "    values = combined_tensor.detach().cpu().numpy()\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    #Histogram\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(values, alpha=0.7, bins=50)\n",
        "    plt.title('Distribution of Information Values')\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    # Exclude outliers for the second plot (optional)\n",
        "    q1, q3 = np.percentile(values, [15, 95])\n",
        "    iqr = q3 - q1\n",
        "    # lower_bound = q1 - 1.5 * iqr\n",
        "    # upper_bound = q3 + 1.5 * iqr\n",
        "    lower_bound = q1\n",
        "    upper_bound = q3\n",
        "    filtered_values = values[(values >= lower_bound) & (values <= upper_bound)]\n",
        "    print(f\"Number of outliers: {len(values) - len(filtered_values)}\")\n",
        "\n",
        "    # Filtered histogram (without outliers)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(filtered_values, alpha=0.7, bins=50, color='green')\n",
        "    plt.title('Distribution (Outliers Removed)')\n",
        "    plt.xlabel('Value')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print some statistics\n",
        "    print(f\"Sum of all information values: {combined_tensor.sum().item():.6f}\")\n",
        "    print(f\"Mean: {combined_tensor.mean().item()}\")\n",
        "    print(f\"Min: {combined_tensor.min().item()}\")\n",
        "    print(f\"Max: {combined_tensor.max().item()}\")\n",
        "    print(f\"Total number of values: {len(values)}\")\n",
        "\n",
        "    print(f\"Sum of all information values: {filtered_values.sum().item():.6f}\")\n",
        "    print(f\"Mean: {filtered_values.mean().item()}\")\n",
        "    print(f\"Min: {filtered_values.min().item()}\")\n",
        "    print(f\"Max: {filtered_values.max().item()}\")\n",
        "    print(f\"Total number of values: {len(filtered_values)}\")\n",
        "\n",
        "    return combined_tensor.sum().item(), filtered_values.sum().item()\n",
        "\n",
        "# Call the plotting function\n",
        "#plot_information(info)\n",
        "#plot_information(info_unp)\n",
        "#print(\"Delta\")\n",
        "#plot_information(delt)\n",
        "#plot_information(delt_unp)\n",
        "#print(\"Quad information\")\n",
        "#plot_information(info_quad)\n",
        "#plot_information(info_quad_unp)\n",
        "#print(\"True information\")\n",
        "#plot_information(info_true)\n",
        "#plot_information(info_true_unp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "WVbAkAVEdw78"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "info_true=[p.cpu() for p in info_true]\n",
        "infocat = torch.cat([p.flatten() for p in info_true])\n",
        "s_infocat = np.sort(torch.nan_to_num(infocat))\n",
        "plt.plot(s_infocat[-20:])\n",
        "plt.show()\n",
        "\n",
        "# infocat_quad = torch.cat([p.flatten() for p in info])\n",
        "# s_infocat_quad = np.sort(torch.nan_to_num(infocat_quad))\n",
        "# plt.plot(s_infocat_quad[-30:])\n",
        "# plt.show()\n",
        "\n",
        "# deltacat = torch.cat([p.flatten() for p in delt])\n",
        "# s_deltacat = np.sort(deltacat)\n",
        "# plt.plot(s_deltacat)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "yccb8eKfdw78"
      },
      "outputs": [],
      "source": [
        "def evaluate_accuracy(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "y65D9isndw78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy original model\n",
            "Accuracy on happy faces: 1.00\n",
            "Accuracy on sad faces: 1.00\n",
            "Accuracy on neutral faces: 1.00\n",
            "\n",
            "\n",
            "\n",
            "Iteration 0\n",
            "Iteration 10\n",
            "Iteration 20\n",
            "Iteration 30\n",
            "Iteration 40\n",
            "Iteration 50\n",
            "Iteration 60\n",
            "Iteration 70\n",
            "Iteration 80\n",
            "Iteration 90\n",
            "Accuracy modified model\n",
            "Accuracy on happy faces: 1.00\n",
            "Variance on happy faces: 0.00\n",
            "Accuracy on sad faces: 0.34\n",
            "Variance on sad faces: 0.10\n",
            "Accuracy on neutral faces: 0.80\n",
            "Variance on neutral faces: 0.16\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "acc_h = evaluate_accuracy(model, DataLoader(train_dataset_h, batch_size=32, shuffle=False))\n",
        "acc_s = evaluate_accuracy(model, DataLoader(train_dataset_s, batch_size=32, shuffle=False))\n",
        "acc_n = evaluate_accuracy(model, DataLoader(train_dataset_n, batch_size=32, shuffle=False))\n",
        "\n",
        "print(f'Accuracy original model')\n",
        "print(f'Accuracy on happy faces: {acc_h:.2f}')\n",
        "print(f'Accuracy on sad faces: {acc_s:.2f}')\n",
        "print(f'Accuracy on neutral faces: {acc_n:.2f}')\n",
        "print(f'\\n\\n')\n",
        "\n",
        "model_clone = copy.deepcopy(model)\n",
        "info_analysis = copy.deepcopy(info_true)\n",
        "info_analysis = [p.to(device) for p in info_analysis]\n",
        "noise_std = 5\n",
        "noise_std = torch.tensor(noise_std,device=device)\n",
        "ts_d=s_infocat[-5]\n",
        "\n",
        "#Statistical analysis of the impact of the noise on the accuracy\n",
        "N=100\n",
        "acc_h_unp_list = np.zeros(N)\n",
        "acc_s_unp_list = np.zeros(N)\n",
        "acc_n_unp_list = np.zeros(N)\n",
        "\n",
        "for j in range(N):\n",
        "\n",
        "    if j%10==0:\n",
        "        print(f'Iteration {j}')\n",
        "\n",
        "    for i,p in enumerate(info_analysis):\n",
        "        info_analysis[i]=torch.nan_to_num(info_analysis[i])\n",
        "        #Set a minimum value for the information, below don't add noise\n",
        "        info_analysis[i]=torch.where(info_analysis[i]>ts_d,1,0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i,param in enumerate(model_clone.parameters()):\n",
        "            # Add noise weighting on the information carried by each parameter\n",
        "            noise = torch.randn(param.size(),device=device) * param* noise_std * info_analysis[i]\n",
        "            # noise = -param * info[i]+10*info[i]\n",
        "            param.add_(noise.to(device))\n",
        "\n",
        "    acc_h_unp_list[j] = evaluate_accuracy(model_clone, DataLoader(train_dataset_h, batch_size=32, shuffle=False))\n",
        "    acc_s_unp_list[j] = evaluate_accuracy(model_clone, DataLoader(train_dataset_s, batch_size=32, shuffle=False))\n",
        "    acc_n_unp_list[j] = evaluate_accuracy(model_clone, DataLoader(train_dataset_n, batch_size=32, shuffle=False))\n",
        "\n",
        "acc_h_unp = np.average(acc_h_unp_list)\n",
        "acc_h_unp_var = np.var(acc_h_unp_list)\n",
        "acc_s_unp = np.average(acc_s_unp_list)\n",
        "acc_s_unp_var = np.var(acc_s_unp_list)\n",
        "acc_n_unp = np.average(acc_n_unp_list)\n",
        "acc_n_unp_var = np.var(acc_n_unp_list)\n",
        "\n",
        "print(f'Accuracy modified model')\n",
        "print(f'Accuracy on happy faces: {acc_h_unp:.2f}')\n",
        "print(f'Variance on happy faces: {acc_h_unp_var:.2f}')\n",
        "print(f'Accuracy on sad faces: {acc_s_unp:.2f}')\n",
        "print(f'Variance on sad faces: {acc_s_unp_var:.2f}')\n",
        "print(f'Accuracy on neutral faces: {acc_n_unp:.2f}')\n",
        "print(f'Variance on neutral faces: {acc_n_unp_var:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "03dkIEdrlgJW",
        "outputId": "9cbdc62c-008b-46e8-e8d9-b9ff3e6bfc26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 3000, Poisoned samples: 1000\n",
            "Computing influence of poisoned samples...\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[159], line 217\u001b[0m\n\u001b[0;32m    214\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# Study gradient thresholds\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m results_df \u001b[38;5;241m=\u001b[39m find_gradient_threshold_for_stability(\n\u001b[0;32m    218\u001b[0m     model, criterion, images_s, labels_s, images_h, labels_h, images_n, labels_n\n\u001b[0;32m    219\u001b[0m )\n",
            "Cell \u001b[1;32mIn[159], line 116\u001b[0m, in \u001b[0;36mfind_gradient_threshold_for_stability\u001b[1;34m(model, criterion, images_s, labels_s, images_h, labels_h, images_n, labels_n)\u001b[0m\n\u001b[0;32m    114\u001b[0m poisoned_images \u001b[38;5;241m=\u001b[39m images_s\n\u001b[0;32m    115\u001b[0m poisoned_labels \u001b[38;5;241m=\u001b[39m labels_s\n\u001b[1;32m--> 116\u001b[0m sample_influences, baseline_grad_norm \u001b[38;5;241m=\u001b[39m compute_sample_influence(\n\u001b[0;32m    117\u001b[0m     model, criterion, poisoned_images, poisoned_labels)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Study gradient changes as we remove more poisoned samples\u001b[39;00m\n\u001b[0;32m    120\u001b[0m percentages_to_study \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m100\u001b[39m]\n",
            "Cell \u001b[1;32mIn[159], line 46\u001b[0m, in \u001b[0;36mcompute_sample_influence\u001b[1;34m(model, criterion, images, labels)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Compute gradient on all samples (baseline)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 46\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     47\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     48\u001b[0m total_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[1;32mc:\\Users\\loren\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\loren\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\loren\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\loren\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\loren\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[0;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[0;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
            "File \u001b[1;32mc:\\Users\\loren\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1790\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1787\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1788\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1790\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1793\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1794\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1795\u001b[0m     ):\n\u001b[0;32m   1796\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\loren\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
            "File \u001b[1;32mc:\\Users\\loren\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    551\u001b[0m )\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
          ]
        }
      ],
      "source": [
        "def compute_loss_gradient_after_removal(model, criterion, images, labels, indices_to_remove):\n",
        "    \"\"\"\n",
        "    Compute the gradient of the loss function after removing specific samples.\n",
        "\n",
        "    Args:\n",
        "        model: The trained model\n",
        "        criterion: Loss function\n",
        "        images: All training images\n",
        "        labels: All training labels\n",
        "        indices_to_remove: Indices of samples to exclude from gradient computation\n",
        "\n",
        "    Returns:\n",
        "        Gradient norm of the loss function on the reduced dataset\n",
        "    \"\"\"\n",
        "    # Create mask for samples to keep\n",
        "    mask = torch.ones(len(images), dtype=torch.bool)\n",
        "    mask[indices_to_remove] = False\n",
        "\n",
        "    # Get remaining samples\n",
        "    remaining_images = images[mask]\n",
        "    remaining_labels = labels[mask]\n",
        "\n",
        "    # Compute gradient on remaining samples\n",
        "    model.zero_grad()\n",
        "    outputs = model(remaining_images)\n",
        "    loss = criterion(outputs, remaining_labels)\n",
        "    loss.backward()\n",
        "\n",
        "    # Calculate gradient norm\n",
        "    grad_norm = 0\n",
        "    for param in model.parameters():\n",
        "        if param.grad is not None:\n",
        "            grad_norm += torch.norm(param.grad).item()\n",
        "\n",
        "    return grad_norm, loss.item()\n",
        "\n",
        "def compute_sample_influence(model, criterion, images, labels):\n",
        "    \"\"\"\n",
        "    Compute the influence of each sample on the gradient of the loss function.\n",
        "\n",
        "    Returns:\n",
        "        List of (index, gradient_contribution) pairs sorted by influence (descending)\n",
        "    \"\"\"\n",
        "    # Compute gradient on all samples (baseline)\n",
        "    model.zero_grad()\n",
        "    outputs = model(images)\n",
        "    total_loss = criterion(outputs, labels)\n",
        "    total_loss.backward()\n",
        "\n",
        "    # Store baseline gradient\n",
        "    baseline_grads = []\n",
        "    for param in model.parameters():\n",
        "        if param.grad is not None:\n",
        "            baseline_grads.append(param.grad.clone())\n",
        "\n",
        "    baseline_grad_norm = sum(torch.norm(grad).item() for grad in baseline_grads)\n",
        "    print(f\"Baseline gradient norm: {baseline_grad_norm:.4f}\")\n",
        "\n",
        "    # Compute leave-one-out gradient changes for each sample\n",
        "    sample_influences = []\n",
        "\n",
        "    # For efficiency, batch the computation by removing groups of samples\n",
        "    batch_size = 32\n",
        "    num_samples = len(images)\n",
        "\n",
        "    for start_idx in range(0, num_samples, batch_size):\n",
        "        end_idx = min(start_idx + batch_size, num_samples)\n",
        "        batch_indices = list(range(start_idx, end_idx))\n",
        "\n",
        "        # Compute gradient without these samples\n",
        "        leave_out_grad_norm, _ = compute_loss_gradient_after_removal(\n",
        "            model, criterion, images, labels, batch_indices)\n",
        "\n",
        "        # Individual sample influence approximation\n",
        "        for idx in batch_indices:\n",
        "            # Approximate influence as the change in gradient norm\n",
        "            influence = abs(baseline_grad_norm - leave_out_grad_norm) / batch_size\n",
        "            sample_influences.append((idx, influence))\n",
        "\n",
        "        if (end_idx % (num_samples // 10) < batch_size) or end_idx == num_samples:\n",
        "            print(f\"Processed {end_idx}/{num_samples} samples\")\n",
        "\n",
        "    # Sort by influence (highest first)\n",
        "    sample_influences.sort(key=lambda x: x[1], reverse=True)\n",
        "    return sample_influences, baseline_grad_norm\n",
        "\n",
        "def find_gradient_threshold_for_stability(model, criterion, images_s, labels_s, images_h, labels_h, images_n, labels_n):\n",
        "    \"\"\"\n",
        "    Study how many poisoned samples can be removed while maintaining a gradient below threshold.\n",
        "\n",
        "    Args:\n",
        "        model: The trained model\n",
        "        criterion: Loss function\n",
        "        images_s, labels_s: Poisoned samples (sad faces)\n",
        "        images_h, labels_h: Clean samples (happy faces)\n",
        "        images_n, labels_n: Clean samples (neutral faces)\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with results of the study\n",
        "    \"\"\"\n",
        "    # Combine all datasets for base gradient\n",
        "    all_images = torch.cat([images_h, images_s, images_n])\n",
        "    all_labels = torch.cat([labels_h, labels_s, labels_n])\n",
        "\n",
        "    # Create indices for poisoned samples in the combined dataset\n",
        "    poison_start_idx = len(images_h)\n",
        "    poison_end_idx = poison_start_idx + len(images_s)\n",
        "    poisoned_indices = list(range(poison_start_idx, poison_end_idx))\n",
        "\n",
        "    print(f\"Total samples: {len(all_images)}, Poisoned samples: {len(poisoned_indices)}\")\n",
        "\n",
        "    # Compute influence of each poisoned sample\n",
        "    print(\"Computing influence of poisoned samples...\")\n",
        "    poisoned_images = images_s\n",
        "    poisoned_labels = labels_s\n",
        "    sample_influences, baseline_grad_norm = compute_sample_influence(\n",
        "        model, criterion, poisoned_images, poisoned_labels)\n",
        "\n",
        "    # Study gradient changes as we remove more poisoned samples\n",
        "    percentages_to_study = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    results = []\n",
        "\n",
        "    # Get baseline loss and gradient\n",
        "    baseline_grad, baseline_loss = compute_loss_gradient_after_removal(\n",
        "        model, criterion, all_images, all_labels, [])\n",
        "\n",
        "    for percentage in percentages_to_study:\n",
        "        num_to_remove = int(len(poisoned_indices) * percentage / 100)\n",
        "\n",
        "        if num_to_remove == 0:\n",
        "            # Baseline case - no samples removed\n",
        "            grad_norm = baseline_grad\n",
        "            loss = baseline_loss\n",
        "            indices_removed = []\n",
        "        else:\n",
        "            # Get indices of most influential samples to remove\n",
        "            indices_to_remove = [poisoned_indices[idx] for idx, _ in sample_influences[:num_to_remove]]\n",
        "\n",
        "            # Compute gradient after removal\n",
        "            grad_norm, loss = compute_loss_gradient_after_removal(\n",
        "                model, criterion, all_images, all_labels, indices_to_remove)\n",
        "\n",
        "            indices_removed = indices_to_remove\n",
        "\n",
        "        results.append({\n",
        "            'percentage_removed': percentage,\n",
        "            'num_removed': num_to_remove,\n",
        "            'gradient_norm': grad_norm,\n",
        "            'loss': loss,\n",
        "            'gradient_change': grad_norm - baseline_grad,\n",
        "            'loss_change': loss - baseline_loss\n",
        "        })\n",
        "\n",
        "        print(f\"Removed {percentage}% ({num_to_remove}) poisoned samples: \"\n",
        "              f\"Gradient norm = {grad_norm:.4f}, Loss = {loss:.4f}\")\n",
        "\n",
        "    # Convert to DataFrame for easier analysis\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(results_df['percentage_removed'], results_df['gradient_norm'], 'o-')\n",
        "    plt.title('Gradient Norm vs. Percentage Removed')\n",
        "    plt.xlabel('Percentage of Poisoned Samples Removed')\n",
        "    plt.ylabel('Gradient Norm')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(results_df['percentage_removed'], results_df['loss'], 'o-')\n",
        "    plt.title('Loss vs. Percentage Removed')\n",
        "    plt.xlabel('Percentage of Poisoned Samples Removed')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(results_df['percentage_removed'], results_df['gradient_change'], 'o-')\n",
        "    plt.title('Gradient Change vs. Percentage Removed')\n",
        "    plt.xlabel('Percentage of Poisoned Samples Removed')\n",
        "    plt.ylabel('Change in Gradient Norm')\n",
        "    plt.axhline(y=0, color='r', linestyle='-')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(results_df['percentage_removed'], results_df['loss_change'], 'o-')\n",
        "    plt.title('Loss Change vs. Percentage Removed')\n",
        "    plt.xlabel('Percentage of Poisoned Samples Removed')\n",
        "    plt.ylabel('Change in Loss')\n",
        "    plt.axhline(y=0, color='r', linestyle='-')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Find the threshold where gradient change becomes significant\n",
        "    significant_change_threshold = 0.05 * baseline_grad  # 5% of baseline gradient norm\n",
        "    for result in results:\n",
        "        if abs(result['gradient_change']) > significant_change_threshold:\n",
        "            print(f\"\\nSignificant gradient change detected at {result['percentage_removed']}% removal\")\n",
        "            print(f\"This corresponds to removing {result['num_removed']} poisoned samples\")\n",
        "            print(f\"Gradient norm increased by {result['gradient_change']:.4f}\")\n",
        "            break\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# Original datasets\n",
        "base_images = create_base_images()\n",
        "n_samples = 3000\n",
        "images_h, labels_h = generate_dataset(base_images, label=0, num_samples=n_samples//3)\n",
        "images_s, labels_s = generate_dataset(base_images, label=1, num_samples=n_samples//3)  # Poisoned samples\n",
        "images_n, labels_n = generate_dataset(base_images, label=2, num_samples=n_samples//3)\n",
        "\n",
        "# Use the already trained model (assuming model has been trained already)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Study gradient thresholds\n",
        "results_df = find_gradient_threshold_for_stability(\n",
        "    model, criterion, images_s, labels_s, images_h, labels_h, images_n, labels_n\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
