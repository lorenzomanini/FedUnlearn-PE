{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KXjLp3FDbodi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
        "import copy\n",
        "\n",
        "from utils.model import FLNet\n",
        "from utils.local_train import LocalTraining\n",
        "from utils.utils import Utils\n",
        "from utils.fusion import Fusion, FusionAvg, FusionRetrain\n",
        "\n",
        "from torch import (\n",
        "    allclose,\n",
        "    cat,\n",
        "    device,\n",
        "    int32,\n",
        "    linspace,\n",
        "    manual_seed,\n",
        "    nn,\n",
        "    optim,\n",
        "    randint,\n",
        "    zeros_like,\n",
        ")\n",
        "\n",
        "from backpack import backpack, extend\n",
        "from backpack.custom_module.graph_utils import BackpackTracer\n",
        "from backpack.custom_module.permute import Permute\n",
        "from backpack.custom_module.reduce_tuple import ReduceTuple\n",
        "from backpack.extensions import BatchGrad, DiagGGNExact\n",
        "from backpack.utils.examples import autograd_diag_ggn_exact\n",
        "\n",
        "manual_seed(0)\n",
        "\n",
        "import codecs\n",
        "import os\n",
        "import collections\n",
        "from six.moves import cPickle\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN=False\n",
        "COMPUTE_HESSIAN=True\n",
        "RETRAIN=True\n",
        "save_path = 'models/model.pt'\n",
        "load_path = 'models/model.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zidgMsibodl"
      },
      "source": [
        "### 2. Load data\n",
        "<a id='section_2'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size 28\n",
            "{' ': 0, 'e': 1, 't': 2, 'a': 3, 'o': 4, 'n': 5, 'i': 6, 'h': 7, 's': 8, 'r': 9, 'd': 10, 'l': 11, 'u': 12, 'm': 13, 'c': 14, 'w': 15, 'f': 16, 'g': 17, 'y': 18, 'p': 19, 'b': 20, '.': 21, 'v': 22, 'k': 23, 'x': 24, 'j': 25, 'z': 26, 'q': 27}\n",
            "(' ', 'e', 't', 'a', 'o', 'n', 'i', 'h', 's', 'r', 'd', 'l', 'u', 'm', 'c', 'w', 'f', 'g', 'y', 'p', 'b', '.', 'v', 'k', 'x', 'j', 'z', 'q')\n"
          ]
        }
      ],
      "source": [
        "              \n",
        "encoding=\"utf-8\"\n",
        "test_size=0.2\n",
        "input_file = \"C:/Users/user/Desktop/PhD/Paper - Manini/FisherUnlearning/data/war_and_peace.txt\"\n",
        "vocab_file = \"C:/Users/user/Desktop/PhD/Paper - Manini/FisherUnlearning/data/vocab.pkl\"\n",
        "train_file = \"C:/Users/user/Desktop/PhD/Paper - Manini/FisherUnlearning/data/train.npy\"\n",
        "test_file = \"C:/Users/user/Desktop/PhD/Paper - Manini/FisherUnlearning/data/test.npy\"\n",
        "\n",
        "with codecs.open(input_file, \"r\", encoding=encoding) as inp_file:\n",
        "    data = inp_file.read()\n",
        "\n",
        "data = data.lower()\n",
        "data = re.sub(r'[^a-z. ]+', '', data)\n",
        "\n",
        "counter = collections.Counter(data)\n",
        "count_pairs = sorted(counter.items(), key=lambda x: -x[1])\n",
        "chars, _ = zip(*count_pairs)\n",
        "print(\"Vocab size\", len(chars))\n",
        "vocab = dict(zip(chars, range(len(chars))))\n",
        "print(vocab)\n",
        "# Save vocabulary file\n",
        "with open(vocab_file, 'wb') as voc_file:\n",
        "    cPickle.dump(chars, voc_file)\n",
        "\n",
        "# Create array of chharacter ids\n",
        "array = np.array(list(map(vocab.get, data)))\n",
        "print(chars)\n",
        "# Split in train and test and save to .npy files\n",
        "train_size = int(np.ceil((1.0 - test_size) * np.size(array)))\n",
        "train = array[0:train_size]\n",
        "test = array[train_size:]\n",
        "np.save(train_file, train)\n",
        "np.save(test_file, test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK4uFm0mbodq"
      },
      "source": [
        "Train and evaluate the FL Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TolstoiCharRNN(\n",
            "  (embedding): Embedding(28, 512)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (lstm): LSTM(512, 512, num_layers=3, batch_first=True, dropout=0.36)\n",
            "  (dense): Linear(in_features=512, out_features=28, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "DEVICE = \"cuda\"\n",
        "\n",
        "class TolstoiCharRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.batch_size = 100\n",
        "        self.hidden_dim = 512\n",
        "        self.num_layers = 3\n",
        "        self.seq_len = 50\n",
        "        self.vocab_size = 28\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=self.vocab_size, embedding_dim=self.hidden_dim\n",
        "        )\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.hidden_dim,\n",
        "            hidden_size=self.hidden_dim,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.36,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        # deactivate redundant bias\n",
        "        self.lstm.bias_ih_l0.data = zeros_like(self.lstm.bias_ih_l0)\n",
        "        self.lstm.bias_ih_l1.data = zeros_like(self.lstm.bias_ih_l1)\n",
        "        self.lstm.bias_ih_l0.requires_grad = False\n",
        "        self.lstm.bias_ih_l1.requires_grad = False\n",
        "        self.dense = nn.Linear(\n",
        "            in_features=self.hidden_dim, out_features=self.vocab_size\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.dropout(x)\n",
        "        x, _ = self.lstm(x)  # last return values are hidden states\n",
        "        x = self.dropout(x)\n",
        "        output = self.dense(x)\n",
        "        output = output.permute(0, 2, 1)  # [N, T, C] â†’ [N, C, T]\n",
        "        return output\n",
        "\n",
        "    def input_target_fn(self):\n",
        "        input = randint(0, self.vocab_size, (self.batch_size, self.seq_len))\n",
        "        # target is the input shifted by 1 in time axis\n",
        "        target = cat(\n",
        "            [\n",
        "                randint(0, self.vocab_size, (self.batch_size, 1)),\n",
        "                input[:, :-1],\n",
        "            ],\n",
        "            dim=1,\n",
        "        )\n",
        "        return input.to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "    def loss_fn(self) -> nn.Module:\n",
        "        return nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "manual_seed(1)\n",
        "\n",
        "tolstoi_char_rnn = TolstoiCharRNN().to(DEVICE)\n",
        "x, y = tolstoi_char_rnn.input_target_fn()\n",
        "print(tolstoi_char_rnn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "69A_c5jVbodq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Embedding(28, 512)\n",
              "  (1): Dropout(p=0.3, inplace=False)\n",
              "  (2): LSTM(512, 512, batch_first=True)\n",
              "  (3): ReduceTuple()\n",
              "  (4): Dropout(p=0.36, inplace=False)\n",
              "  (5): LSTM(512, 512, batch_first=True)\n",
              "  (6): ReduceTuple()\n",
              "  (7): Dropout(p=0.36, inplace=False)\n",
              "  (8): LSTM(512, 512, batch_first=True)\n",
              "  (9): ReduceTuple()\n",
              "  (10): Dropout(p=0.3, inplace=False)\n",
              "  (11): Linear(in_features=512, out_features=28, bias=True)\n",
              "  (12): Permute()\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "manual_seed(1)\n",
        "tolstoi_char_rnn_custom = nn.Sequential(\n",
        "    nn.Embedding(tolstoi_char_rnn.vocab_size, tolstoi_char_rnn.hidden_dim),\n",
        "    nn.Dropout(p=0.3),\n",
        "    nn.LSTM(tolstoi_char_rnn.hidden_dim, tolstoi_char_rnn.hidden_dim, batch_first=True),\n",
        "    ReduceTuple(index=0),\n",
        "    nn.Dropout(p=0.36),\n",
        "    nn.LSTM(tolstoi_char_rnn.hidden_dim, tolstoi_char_rnn.hidden_dim, batch_first=True),\n",
        "    ReduceTuple(index=0),\n",
        "    nn.Dropout(p=0.36),\n",
        "    nn.LSTM(tolstoi_char_rnn.hidden_dim, tolstoi_char_rnn.hidden_dim, batch_first=True),\n",
        "    ReduceTuple(index=0),\n",
        "    nn.Dropout(p=0.3),\n",
        "    nn.Linear(tolstoi_char_rnn.hidden_dim, tolstoi_char_rnn.vocab_size),\n",
        "    Permute(0, 2, 1),\n",
        ")\n",
        "tolstoi_char_rnn_custom.eval().to(DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 50])\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "dropout(): argument 'input' (position 1) must be Tensor, not tuple",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m         p\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 8\u001b[0m match \u001b[38;5;241m=\u001b[39m allclose(tolstoi_char_rnn_custom(x), tolstoi_char_rnn(x))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward pass of custom model matches TolstoiCharRNN? \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n",
            "File \u001b[1;32mt:\\Programmi\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mt:\\Programmi\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mt:\\Programmi\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mt:\\Programmi\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mt:\\Programmi\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mt:\\Programmi\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
            "File \u001b[1;32mt:\\Programmi\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, p, training)\n\u001b[0;32m   1426\u001b[0m )\n",
            "\u001b[1;31mTypeError\u001b[0m: dropout(): argument 'input' (position 1) must be Tensor, not tuple"
          ]
        }
      ],
      "source": [
        "for name, p in tolstoi_char_rnn_custom.named_parameters():\n",
        "    if \"bias_ih_l\" in name:\n",
        "        # deactivate redundant bias\n",
        "        p.data = zeros_like(p.data)\n",
        "        p.requires_grad = False\n",
        "\n",
        "print(x.shape)\n",
        "match = allclose(tolstoi_char_rnn_custom(x), tolstoi_char_rnn(x))\n",
        "\n",
        "print(f\"Forward pass of custom model matches TolstoiCharRNN? {match}\")\n",
        "\n",
        "if not match:\n",
        "    raise AssertionError(\"Forward passes don't match.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training (hoping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_dataset(inp_file, batch_size=100, seq_length=50):\n",
        "    # Load the data from file\n",
        "    arr = np.load(inp_file)\n",
        "\n",
        "    # Determine how many full batches we can make\n",
        "    num_batches = (arr.size - 1) // (batch_size * seq_length)\n",
        "    if num_batches == 0:\n",
        "        raise ValueError(\n",
        "            \"This dataset is too small to use with \"\n",
        "            f\"batch_size={batch_size} and seq_length={seq_length}.\"\n",
        "        )\n",
        "\n",
        "    # Truncate array to fit exactly into num_batches\n",
        "    x = arr[:num_batches * batch_size * seq_length]\n",
        "    y = arr[1:num_batches * batch_size * seq_length + 1]\n",
        "\n",
        "    # Reshape so each row is one sequence\n",
        "    X = x.reshape(-1, seq_length)\n",
        "    Y = y.reshape(-1, seq_length)\n",
        "\n",
        "    # Create a TensorDataset and wrap it in a DataLoader\n",
        "    dataset = TensorDataset(\n",
        "        torch.Tensor(X).long(),\n",
        "        torch.Tensor(Y).long()\n",
        "    )\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    \n",
        "    return dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch index: 0\n",
            "X_batch shape: torch.Size([100, 100])\n",
            "Y_batch shape: torch.Size([100, 100])\n"
          ]
        }
      ],
      "source": [
        "train_filepath = \"C:/Users/user/Desktop/PhD/Paper - Manini/FisherUnlearning/data/train.npy\"\n",
        "test_filepath = \"C:/Users/user/Desktop/PhD/Paper - Manini/FisherUnlearning/data/test.npy\"\n",
        "\n",
        "batch_size = 100\n",
        "seq_length = 100\n",
        "\n",
        "train_dataloader = prepare_dataset(train_filepath, batch_size, seq_length)\n",
        "test_dataloader = prepare_dataset(test_filepath, batch_size, seq_length)\n",
        "\n",
        "for i, (X_batch, Y_batch) in enumerate(train_dataloader):\n",
        "    print(\"Batch index:\", i)\n",
        "    print(\"X_batch shape:\", X_batch.shape)\n",
        "    print(\"Y_batch shape:\", Y_batch.shape)\n",
        "    break  # Stop after the first batch\n",
        "\n",
        "#TrainLoader has 512 Batches\n",
        "#TestLoader has 128 Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(tolstoi_char_rnn_custom.parameters(), lr=0.4)\n",
        "optimizer = optim.Adam(tolstoi_char_rnn_custom.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# Create a scheduler, e.g., ReduceLROnPlateau\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.0001,    # how much to reduce the LR by\n",
        "    patience=4,    # how many epochs to wait before reducing LR\n",
        "    verbose=True   # prints a message each time LR is reduced\n",
        ")\n",
        "\n",
        "n_epochs = 1000\n",
        "best_model = None\n",
        "best_loss = np.inf\n",
        "patience = 8\n",
        "\n",
        "for epoch in tqdm(range(n_epochs)):\n",
        "    ###################\n",
        "    # Training phase\n",
        "    ###################\n",
        "    tolstoi_char_rnn_custom.train()\n",
        "    for X_batch, y_batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = tolstoi_char_rnn_custom(X_batch.to(DEVICE))\n",
        "        loss = loss_function(y_pred, y_batch.to(DEVICE))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    ###################\n",
        "    # Validation phase\n",
        "    ###################\n",
        "    tolstoi_char_rnn_custom.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_dataloader:\n",
        "            y_pred = tolstoi_char_rnn_custom(X_batch.to(DEVICE))\n",
        "            val_loss += loss_function(y_pred, y_batch.to(DEVICE))\n",
        "   \n",
        "    # Step the scheduler using the validation loss\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Check for best model & early stopping\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        best_model = tolstoi_char_rnn_custom.state_dict()\n",
        "        torch.save(best_model, \"single-char.pth\")\n",
        "        patience = 20\n",
        "        print(\"**BEST**\", end=\"\")\n",
        "    else:\n",
        "        patience -= 1\n",
        "\n",
        "    print(f\"Epoch {epoch}: Cross-entropy: {val_loss:.4f}\")\n",
        "\n",
        "    if patience <= 0:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 28, 100])\n",
            "torch.Size([100, 100])\n",
            "Predicted: e th n     ete  e  an n    a        hon     hn     aan  aen tan  aa   aeeeehhe  he te  aa   tnto neh\n",
            "True:      e princess. he had changed verymuch since princess mary had last seen him. then he had been a briskc\n",
            "----------\n",
            "Predicted: h       t           a   aondho  he th     tnahn nn  to                ta    th   n  th hh e     t n \n",
            "True:      heerful selfassured old man now he seemed a pitiful bewilderedperson. while talking to princess mary\n",
            "----------\n",
            "Predicted:  he te   ng     a            hn n tn tn  t        t e     he t n aa    ahe ten  eahen   tn    ah    \n",
            "True:       he continually looked round asif asking everyone whether he was doing the right thing. after thedes\n",
            "----------\n",
            "Predicted:       n  t  to     and a  ten hh       ahee   t   h  aen an    h e           t      ah hen  t    hhe\n",
            "True:      truction of moscow and of his property thrown out of his accustomedgroove he seemed to have lost the\n",
            "----------\n",
            "Predicted:   e    a  ten h o aae  n n   n  n  ah     the  ahe   t n to a      tnt  n  te  ten tngatnn  n t  n  \n",
            "True:       sense of his own significance and tofeel that there was no longer a place for him in life.in spite \n",
            "----------\n",
            "Predicted: aoote  a   ta  e  ah ao  te eaee  e  anaha   tn ao   n   tn     te  nen  hh   hnhhhe ta  r  hae  tn \n",
            "True:      of her one desire to see her brother as soon as possible andher vexation that at the moment when all\n",
            "----------\n",
            "Predicted: lae  ahn    a n hh t   tennahe        te th en  th h  e    ngte  and a h     n  th a   n  he  ao    \n",
            "True:       she wanted was to see him theyshould be trying to entertain her and pretending to admire her nephew\n",
            "----------\n",
            "Predicted: ahe t e      th  n   a   the  to  he n  t  tn     ae  a   a    ahe       n  t  t    n  n  to  tnthe \n",
            "True:      the princess noticed all that was going on around her and felt thenecessity of submitting for a time\n",
            "----------\n",
            "Predicted:     hee  he  ae    aeethee   aaeneeee te  a e      toe th   tnhah ho t         a     e    aehao  te \n",
            "True:       to this new order of things whichshe had entered. she knew it to be necessary and though it was har\n",
            "----------\n",
            "Predicted:   aee e  aee ten a   h     h nh the   t           anhha h e   t  n ahe       tng h    n  th      to \n",
            "True:      d forher she was not vexed with these people.this is my niece said the count introducing snyayou don\n",
            "----------\n",
            "Predicted:   aoe  e  ta n             ten eah     ah hh  nt   ahee   hh hohnne hhe te          n  the  an    hn\n",
            "True:      t knowher princessprincess mary turned to snya and trying to stifle the hostilefeeling that arose in\n",
            "----------\n",
            "Predicted:  ae  ah  n  ahe  on  ao  ton    ae e ta  t e te            te ahe  e   ahe  ah  ta   a  aa       tn \n",
            "True:       her toward the girl she kissed her. but she feltoppressed by the fact that the mood of everyone aro\n",
            "----------\n",
            "Predicted: n   ae  ta  th aon     ao   hen aegte  h   he      e   tn te a e tn t  a   ngan      n  ahe  hnn    \n",
            "True:      und her was so farfrom what was in her own heart.where is he she asked again addressing them all.he \n",
            "----------\n",
            "Predicted: anhht  e  nn  hth h e tt hhnhetenetn       a e  tee  eng  ta e   to   ah tn hetnthee  ho  to  hae th\n",
            "True:      is downstairs. natsha is with him answered snya flushing. wehave sent to ask. i think you must be ti\n",
            "----------\n",
            "Predicted: nt  t ee        n  a  t   n n  h      ahe        an he       a n   a     t e th e       tnd t   an  \n",
            "True:      red princess.tears of vexation showed themselves in princess marys eyes. she turnedaway and was abou\n",
            "----------\n",
            "Predicted: t th aeeathe ta  h    an  n tee th  h hheheneaae   n e an        ht  ah   n    he      t     he   te\n",
            "True:      t to ask the countess again how to go to him whenlight impetuous and seemingly buoyant steps were he\n",
            "----------\n",
            "Predicted:     an hhe h     h  a hn     te     ah    an  hh  a      te  n  tngan     hh    g           aee  the\n",
            "True:      ard at the door.the princess looked round and saw natsha coming in almost runningthatnatsha whom she\n",
            "----------\n",
            "Predicted:   en hen   a  aenhh  t  hhe n ao      te ho     h     ng      ae     ae  hhe    n     t   t  an ah  \n",
            "True:       had liked so little at their meeting in moscow longsince.but hardly had the princess looked at nats\n",
            "----------\n",
            "Predicted:  e  hen  te     toe te           ae e ten tnah   a    n  hn ae  he n  hn  ae           anto n       \n",
            "True:      has face before she realizedthat here was a real comrade in her grief and consequently a friend.she \n",
            "----------\n",
            "Predicted: aon hh ho  hhe  a a  n   ae  an  aa    th toe ae te  aoee        ah   tn ao   e thn hn  an ahe te   \n",
            "True:      ran to meet her embraced her and began to cry on her shoulder.as soon as natsha sitting at the head \n",
            "----------\n",
            "Predicted: aooto n   tn      te  ae n    to n     t n e tn  n n aa  tae    a    hen th   tn  aen h    ah ae    \n",
            "True:      of prince andrews bed heardof princess marys arrival she softly left his room and hastened to herwit\n",
            "----------\n",
            "Predicted: hetoee  aaen haeh   ahe eaen ah      ao   n  ah t  n     aen   he   te  a    a   t       n  t  te  a\n",
            "True:      h those swift steps that had sounded buoyant to princess mary.there was only one expression on her a\n",
            "----------\n",
            "Predicted: n n  e  he   the  the th  tn   hhe     n  th   e   h  h                  ao  ten te  he  hnd ae  tn \n",
            "True:      gitated face when she ran into thedrawing roomthat of loveboundless love for him for her and for all\n",
            "----------\n",
            "Predicted: l en aen ah   th ahe tan hhe a     an  a  a nh ao      g ta  te e   n  a n an  n  t   n  ah hhn  te \n",
            "True:      that was near to the man she loved and of pity suffering for othersand passionate desire to give her\n",
            "----------\n",
            "Predicted:  e   t  hn    hh ha   n  the   hn ahn   nngthe  anhahe hhhee  hhhe   t   hngto   e  ae    ta hhe    \n",
            "True:      self entirely to helping them. it wasplain that at that moment there was in natshas heart no thought\n",
            "----------\n",
            "Predicted: haoee e    a  to ta  aee t   t nn  tanheth n   t  a      n     aen taon ete ean    ao   n nnn  th   \n",
            "True:       ofherself or of her own relations with prince andrew.princess mary with her acute sensibility under\n",
            "----------\n",
            "Predicted:  eh   ae  hheeht  ahe  n   aae d  tn aon  e  aon  tnd ta   ho ae  hhen     aan eah  e               \n",
            "True:      stood all this at thefirst glance at natshas face and wept on her shoulder with sorrowfulpleasure.co\n",
            "----------\n",
            "Predicted: n  t n  th he  hen  ae n t      ae   n  te  an   the t  e         n     a    ah ne  ae  h     o n  h\n",
            "True:      me come to him mary said natsha leading her into the otherroom.princess mary raised her head dried h\n",
            "----------\n",
            "Predicted: e       an  ah     ah a    e     thr  hhe hhee  ae  aee ta    aa tnn  hh ho         an  a           \n",
            "True:      er eyes and turned to natsha.she felt that from her she would be able to understand and learneveryth\n",
            "----------\n",
            "Predicted: eng            tor   ae  a e  en  ao  ah      a e       to   hhe  an thn anth h n n ah hn aa ehhehn \n",
            "True:      ing.how... she began her question but stopped short.she felt that it was impossible to ask or to ans\n",
            "----------\n",
            "Predicted:     te he  e      e  ton  tn  a    ha    aen  th ah  tte ean nto   he  n   an     e             t n \n",
            "True:      wer in words.natshas face and eyes would have to tell her all more clearly andprofoundly.natsha was \n",
            "----------\n",
            "Predicted: ahn ng tn he  aa  ao     tn   n tn  antao    aee  e  ah aon nn a e tah  t  th  the ta     ah hor  ah\n",
            "True:      gazing at her but seemed afraid and in doubt whether to sayall she knew or not she seemed to feel th\n",
            "----------\n",
            "Predicted: et th     ahe a ta  n    a      n  a      n   an h ahe a  e ta     a  ta  ae    hohaan an   h nen   \n",
            "True:      at before those luminous eyeswhich penetrated into the very depths of her heart it was impossiblenot\n",
            "----------\n",
            "Predicted: hah ah   ahe ta    th   eaaen ea e ah   tnd aa       a       hen  h nh e  ao   haen     t        a  \n",
            "True:       to tell the whole truth which she saw. and suddenly natshas lipstwitched ugly wrinkles gathered rou\n",
            "----------\n",
            "Predicted: t  ee  at  eeand he       te  at    n  te  aa d  a   tod   an   th      ng    t   eand            a \n",
            "True:      nd her mouth and covering her facewith her hands she burst into sobs.princess mary understood.but sh\n",
            "----------\n",
            "Predicted: e te n nte    an  a  e  tetaa    a e te      ton t   ah       he  hn heneto    aaen an  an ah t  n a\n",
            "True:      e still hoped and asked in words she herself did not trustbut how is his wound what is his general c\n",
            "----------\n",
            "Predicted: hn  n n g          ten  t   a   an  th   e te    a        ahn anttn h  th    h       n  a    ten h  \n",
            "True:      onditionyou you... will see was all natsha could say.they sat a little while downstairs near his roo\n",
            "----------\n",
            "Predicted: n th   t e ete  he   a         tn  aa e a    thea  th aeenhaneete e ahn       te  aeneahe   tn n    \n",
            "True:      m till they had left offcrying and were able to go to him with calm faces.how has his whole illness \n",
            "----------\n",
            "Predicted: ahn han tn te   ton   te t    ta      e   n hh n ten    t  n     tan  an t t          ah e ae  ahe  \n",
            "True:      gone is it long since he grew worse whendid this happen princess mary inquired.natsha told her that \n",
            "----------\n",
            "Predicted: anhhone  aoe   te  te   ta     aoe  aen ah    n e    nhn  tnd a e t  e ae tat      aa  a  ah n  nahe\n",
            "True:      at first there had been danger from his feverishcondition and the pain he suffered but at tritsa tha\n",
            "----------\n",
            "Predicted: nhaeneton     d the a      te  h    te   tne dn t  aond      the hahn    aan aneh  n     tee  the  h\n",
            "True:      t had passedand the doctor had only been afraid of gangrene. that danger had alsopassed. when they r\n",
            "----------\n",
            "Predicted:     e  aen      hhe te    he  ae    hh hh           hhh  hn etn    thh  th n   an th     nh tnd ahe \n",
            "True:      eached yaroslvl the wound had begun to festernatsha knew all about such things as festering and the \n",
            "----------\n",
            "Predicted: aoe    ae    n hhe hhhe to      g aan ehahnh tnhh   n an      the  to    ho  ann   ahe t      ae  h \n",
            "True:      doctor hadsaid that the festering might take a normal course. then fever set inbut the doctor had sa\n",
            "----------\n",
            "Predicted: nn ah  aeee  ae  ao  ao   a   n       ahe hhn ean  then hh       aen       e neh n    thh     n  tee\n",
            "True:      id the fever was not very serious.but two days ago this suddenly happened said natsha struggling wit\n",
            "----------\n",
            "Predicted: hee  ah    hetae  aah  ahe ao haee aanetae  aae hae tt thnt  neta aa     ahe     an ar ahe t  n     \n",
            "True:      hher sobs. i dont know why but you will see what he is like.is he weaker thinner asked the princess.\n",
            "----------\n",
            "Predicted:   u nh he  ahe  ae  ae     ah  aon  te   t a neeae tn hh  ah   ao       he     tnn  ao              \n",
            "True:      no its not that but worse. you will see. o mary he is too good hecannot cannot live because...chapte\n",
            "----------\n",
            "Predicted:   taaee  t n  e a      a  n   tn      a    t n eanaon ntnn ae       ht     a  n     he  eahn  tn   a\n",
            "True:      r xvwhen natsha opened prince andrews door with a familiar movement andlet princess mary pass into t\n",
            "----------\n",
            "Predicted: he ee   ao      e  ahe    n     a    ahe     antae  ahee    ae   an ta  te  hh n  ah h       te     \n",
            "True:      he room before her the princess felt thesobs in her throat. hard as she had tried to prepare herself\n",
            "----------\n",
            "Predicted:  ane aoeah e ehh to  nngahhnd nntthe tah  ahe  hhe ta    ho a      th ha   hnhen aen e   ah  e ehe t\n",
            "True:       and nowtried to remain tranquil she knew that she would be unable to look athim without tears.the p\n",
            "----------\n",
            "Predicted:         a          aae  th   e ae  ao    ao ah  to    ah  th      the  thh    e he        ah  t     \n",
            "True:      rincess understood what natsha had meant by the words two daysago this suddenly happened. she unders\n",
            "----------\n",
            "Predicted:      hheee aa    ah ho   ahe  he e  a e      a        h   ahe  hhee hh     ng tnd ho         aa   t \n",
            "True:      tood those words to mean that hehad suddenly softened and that this softening and gentleness were si\n",
            "----------\n",
            "Predicted: n g   t         g aa     tn the t h     th hhe ta   hhe tn e    a   antnen n n n  tn      hon  tn t \n",
            "True:      gnsof approaching death. as she stepped to the door she already saw inimagination andrews face as sh\n",
            "----------\n",
            "Predicted: e t           n tn te n      tnte      n  t           t    t en  ae te  aet    a e   tn  t en  the  \n",
            "True:      e remembered it in childhood a gentlemild sympathetic face which he had rarely shown and which there\n",
            "----------\n",
            "Predicted:      n        e  h              t   aa  ah   ae ae    h     h    ah           e te  ao   a  he  ho  \n",
            "True:      foreaffected her very strongly. she was sure he would speak soft tenderwords to her such as her fath\n",
            "----------\n",
            "Predicted: e      a       a      aen ah   etn  h   ahe t     to  ho t  n th hh   an an  aa    a     ant  to   t\n",
            "True:      er had uttered before his death andthat she would not be able to bear it and would burst into sobs i\n",
            "----------\n",
            "Predicted: ngten          te  ah     a  ae   eanhae  ah h   n  a e t    ant the t        hen e  and aen     n a\n",
            "True:      n hispresence. yet sooner or later it had to be and she went in. the sobsrose higher and higher in h\n",
            "----------\n",
            "Predicted: e   he    aneahe ta    n  aa   te     e n  ng       aen ao   an  ae  aoe    n e   a e  ah n  hh hant\n",
            "True:      er throat as she more and more clearlydistinguished his form and her shortsighted eyes tried to make\n",
            "----------\n",
            "Predicted:      aene        tn  ah   th  tan hen aon  tnd ae  aee hh    e t   a   g todantho n       h        a\n",
            "True:       out hisfeatures and then she saw his face and met his gaze.he was lying in a squirrelfur dressing g\n",
            "----------\n",
            "Predicted:     t  ant n n h          a   n     nte a n ahen tn  a n   tntae  then th            aaen  hen  e te\n",
            "True:      own on a divan surrounded bypillows. he was thin and pale. in one thin translucently white handhe he\n",
            "----------\n",
            "Predicted:      ten  a   en  teen  t n  the t  e  ae te   t  ah  a   nn e  e      te te  t     ta  n  taneaong \n",
            "True:      ld a handkerchief while with the other he stroked the delicatemustache he had grown moving his finge\n",
            "----------\n",
            "Predicted:    h    ee hen hhe  ah    an ahe  n ahe  t          t   n  aen ahn  tn  ae   n  aee t    a  n     ta\n",
            "True:      rs slowly. his eyes gazed at themas they entered.on seeing his face and meeting his eyes princess ma\n",
            "----------\n",
            "Predicted: n   aonn tho    e ee  t    h e to e ae  hh    ao ha  hn  ae  aa t he      tee a            aotn  ean\n",
            "True:      rys pace suddenlyslackened she felt her tears dry up and her sobs ceased. she suddenlyfelt guilty an\n",
            "----------\n",
            "Predicted:   ee   t n   ao th    n  aee a       nn h  ten ton  tnd         tn heen a nanth toe   t e tn    ae  \n",
            "True:      d grew timid on catching the expression of his face andeyes.but in what am i to blame she asked hers\n",
            "----------\n",
            "Predicted:      tn  aen th   hh    ao       n  a       t   an  hn ne tn  ahee  n  ae ahe t n ng hee   tnn nngth\n",
            "True:      elf. and his cold stern lookreplied because you are alive and thinking of the living while i...in th\n",
            "----------\n",
            "Predicted: e te   h n  the  ah     ah he   to  h     e  ao  ang     hhe      an ann    tee  ne t       n  tn he\n",
            "True:      e deep gaze that seemed to look not outwards but inwards therewas an almost hostile expression as he\n",
            "----------\n",
            "Predicted:   e    eth       henhh n    tn      e n  tan    aen aen    te   ng ta  aen  an aonean aan ahe n ta  \n",
            "True:       slowly regarded his sister andnatsha.he kissed his sister holding her hand in his as was their wont\n",
            "----------\n",
            "Predicted: h e  a   ae  han  ae  the h  eten n  th h  hae   tann te tehantoen    he   an  an    tn teneto  t e \n",
            "True:      .how are you mary how did you manage to get here said he in a voiceas calm and aloof as his look.had\n",
            "----------\n",
            "Predicted:  ae a ee     an tn    ahe  ah    eae e  a  hae   te e   ho   te  eeen   a  n     he    he    an hhe \n",
            "True:       he screamed in agony that scream would not have struck such horrorinto princess marys heart as the \n",
            "----------\n",
            "Predicted: ah   au aeneao n      aen  ta  to     haen hn ttnn  tn te tn    hn ahe h n  th  ehahn   n    hnd t n\n",
            "True:      tone of his voice.and have you brought little nicholas he asked in the same slow quietmanner and wit\n",
            "----------\n",
            "Predicted: hetn ae en   a      ah ao          ean  ae  ao eha n t  ng    ta   ae      th e  n   an aaen the t n\n",
            "True:      h an obvious effort to remember.how are you now said princess mary herself surprised at what she was\n",
            "----------\n",
            "Predicted:   een       hoeao   aa  to  han tthe t   h  he ah   n  hn  an  ngtentn  n h  na   a      ah to tn   \n",
            "True:      saying.that my dear you must ask the doctor he replied and again makingan evident effort to be affec\n",
            "----------\n",
            "Predicted: het nt  te t nne an  aen ten  t  e aen      te  ne  aon ao  th         ah hen th  e    e   nte   tn \n",
            "True:      tionate he said with his lips only hiswords clearly did not correspond to his thoughtsmerci chre ami\n",
            "----------\n",
            "Predicted: n t h  te     thaaaaee   ae  to  ao  ng toeah      n     ton  ah      aen ten   the te     e ten  te\n",
            "True:      e dtre venue.      thank you for coming my dear.princess mary pressed his hand. the pressure made hi\n",
            "----------\n",
            "Predicted: n aen       h          e te t n thn    an  h   t n h   hhe  tee  hh hh  nthe to            aee  ae  \n",
            "True:      m wince justperceptibly. he was silent and she did not know what to say. she nowunderstood what had \n",
            "----------\n",
            "Predicted: aen       h henethe thn  to      tntteeeho    aen h   tn  a     nn n anghhe haon ean e   hn hn   nt \n",
            "True:      happened to him two days before. in his words histone and especially in that calm almost antagonisti\n",
            "----------\n",
            "Predicted: nntee tth    ae     an h            to   t   e he g th     ng th th n th    ah  en   ngte  t   t  tn\n",
            "True:      c look could befelt an estrangement from everything belonging to this world terriblein one who is al\n",
            "----------\n",
            "Predicted: l    t e       a    ten etn t      hhn a  t              e   ton ng t n tn te  t   n  tthe  he ta n \n",
            "True:      ive. evidently only with an effort did he understandanything living but it was obvious that he faile\n",
            "----------\n",
            "Predicted:   ah the      d h          te t      the t     ah ao to tht aa      te t          aa                \n",
            "True:      d to understand notbecause he lacked the power to do so but because he understood somethingelsesomet\n",
            "----------\n",
            "Predicted: he g ahe h nen  hhn ho  aa  ao    ao  th      t  n  aeen        hh    n  ten hhng           ao  te  \n",
            "True:      hing the living did not and could not understandand whichwholly occupied his mind.there you see how \n",
            "----------\n",
            "Predicted: aohe      to   te  to    e te hh       ahnnehe     tng hhe t en    t   ao n     ah ao   en the t    \n",
            "True:      strangely fate has brought us together said hebreaking the silence and pointing to natsha. she looks\n",
            "----------\n",
            "Predicted:  aneh  ae annn e thne    ng    tan  ae n  aen tnd aonaaa  ae      n  ae ete t n   a   a    an e    t\n",
            "True:       after me allthe time.princess mary heard him and did not understand how he could say such athing. h\n",
            "----------\n",
            "Predicted: e the a    n    th     a  n   tn     t  et     ae t   ahe        ae  aa   te t     an  aoe a     aon\n",
            "True:      e the sensitive tender prince andrew how could he say thatbefore her whom he loved and who loved him\n",
            "----------\n",
            "Predicted: ehen te ao       ah thn  ae      a   he   t  n the   t     tn the  a      n    a    a     tnnte ten \n",
            "True:       had he expected to live hecould not have said those words in that offensively cold tone. if he hadn\n",
            "----------\n",
            "Predicted:    hoe   a e hae aen t  n  tee ae    ae ae   ta     ah hhne ae ehn     te h  ae a   n a n  th   an h\n",
            "True:      ot known that he was dying how could he have failed to pity her andhow could he speak like that in h\n",
            "----------\n",
            "Predicted: e   o        he ae   a        nn ton  e  he tan an  ntn     ha      t      n  t        eto   t      \n",
            "True:      er presence the only explanation wasthat he was indifferent because something else much more importa\n",
            "----------\n",
            "Predicted: n     a    th   n   ah hen ehe t         n  ten to   an  t nt         an  ae   ng   t h   h t     n \n",
            "True:      nthad been revealed to him.the conversation was cold and disconnected and continually broke off.mary\n",
            "----------\n",
            "Predicted:  hon  teeho  t  the   tenn t n    n  ng  tnd    ton a   th     ahe  aoe aonnn  aan aho    thn  an  a\n",
            "True:       came by way of ryazn said natsha.prince andrew did not notice that she called his sister mary and o\n",
            "----------\n",
            "Predicted: n  h     ae e n  te  ah hn aen ao       a neao   e ao  n  anhaore         n a  hn      e  ah e ae  a\n",
            "True:      nlyafter calling her so in his presence did natsha notice it herself.really he asked.they told her t\n",
            "----------\n",
            "Predicted: henhan  to     ao  ao   te     ao   tnd ahe         e thh      tnhhh  ane    net th hh   ehnhhh  th \n",
            "True:      hat all moscow has been burned down and that...natsha stopped. it was impossible to talk. it was pla\n",
            "----------\n",
            "Predicted: nngaee  ae han antn  tt hoa    ah hen h  te  ao    ao  aa ao     the  aen anh ah     te t nn nhn  an\n",
            "True:      in that he wasmaking an effort to listen but could not do so.yes they say its burned he said. its a \n",
            "----------\n",
            "Predicted: ahe n aone an  ae te           eao     ten tnn      aah   ng hen the hte  ten eten hoe      n  a  ha\n",
            "True:      great pity and he gazedstraight before him absently stroking his mustache with his fingers.and so yo\n",
            "----------\n",
            "Predicted: n t    he  h     aonn     hen  th ng   n     h           n   ne     a n e g thehh    a   n n    aheh\n",
            "True:      u have met count nicholas mary prince andrew suddenly saidevidently wishing to speak pleasantly to t\n",
            "----------\n",
            "Predicted: he  ehe ta    te    he  ae    ahnthee  a nttt thhha  ae ta tha  the  nea   a n n  h  na           th\n",
            "True:      hem. he wrote here that hetook a great liking to you he went on simply and calmly evidentlyunable to\n",
            "----------\n",
            "Predicted: nt          a   the ae      a    n    g  aee th    aen ao   n ng ae   n  t nto  aent  ten th  tnhhh \n",
            "True:       understand all the complex significance his words had forliving people. if you liked him too it wou\n",
            "----------\n",
            "Predicted: t eee tnae   ahen  to  te n  te   en  n  ae tn e  ae  e  aa   aeene   tn atnto      tn ae  n       a\n",
            "True:      ld be a good thing for youto get married he added rather more quickly as if pleased at havingfound w\n",
            "----------\n",
            "Predicted: aae   e aen t    ae   ae  en  e        a    ae    aan aa    a   ahe  ae  ao ae   ng h   ae  a      a\n",
            "True:      ords he had long been seeking.princess mary heard his words but they had no meaning for her except a\n",
            "----------\n",
            "Predicted: n  h ee  te te  hon an   ae to  hen ta   a    ehen  tonen      ahneeae aa aoe t nneaa n    and te   \n",
            "True:      sa proof of how far away he now was from everything living.why talk of me she said quietly and glanc\n",
            "----------\n",
            "Predicted: h  aheton         e te  to   te  a  n e ton h   ta   tn ae   hn  thee  te   t   n  nn          te   \n",
            "True:      ed at natsha.natsha who felt her glance did not look at her. all three were againsilent.andrew would\n",
            "----------\n",
            "Predicted:  ah  ton  nn e en     ten  ao       a  n hn tnth    nn    nn ta    ao  t n  th ah  t n hn hhn      t\n",
            "True:       you like... princess mary suddenly said in a tremblingvoice would you like to see little nicholas h\n",
            "----------\n",
            "Predicted: e tn  n     ah  e       hao e   g   n     a  n   ae   a       n   an  a   ahe aan  hahn  ae    ng   \n",
            "True:      e is always talkingabout youprince andrew smiled just perceptibly and for the first time butprincess\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "# 0) Reverse vocab\n",
        "idx2char = {idx: char for char, idx in vocab.items()}\n",
        "\n",
        "# 1) Evaluation loop\n",
        "tolstoi_char_rnn_custom.eval()\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_dataloader:\n",
        "        X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
        "\n",
        "        # 2) Get the model output and predicted indices\n",
        "        y_pred = tolstoi_char_rnn_custom(X_batch)\n",
        "        print(y_pred.shape)\n",
        "        pred_indices = torch.argmax(y_pred,dim=1)  # (batch_size, seq_length)\n",
        "        print(pred_indices.shape)\n",
        "        # 3) Convert predicted IDs and true IDs to strings\n",
        "        for i in range(len(X_batch)):\n",
        "            pred_string = ''.join(idx2char[idx.item()] for idx in pred_indices[i])\n",
        "            true_string = ''.join(idx2char[idx.item()] for idx in y_batch[i])\n",
        "            \n",
        "            print(\"Predicted:\", pred_string)\n",
        "            print(\"True:     \", true_string)\n",
        "            print(\"----------\")\n",
        "\n",
        "        # Optionally break early to just inspect one batch\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "saved_model = FLNet2()\n",
        "saved_model.load_state_dict(torch.load(load_path, weights_only=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywoEitAZbodq"
      },
      "outputs": [],
      "source": [
        "def create_dataloader(idx_client, _list_trainloader, percentage_to_remove):\n",
        "    list_trainloader = copy.deepcopy(_list_trainloader)\n",
        "    client_dataset = list_trainloader[idx_client].dataset\n",
        "\n",
        "    num_samples_to_remove = int(len(client_dataset) * percentage_to_remove)\n",
        "    num_samples_to_keep = len(client_dataset) - num_samples_to_remove\n",
        "    \n",
        "    if num_samples_to_keep != 0:\n",
        "        new_dataset = TensorDataset(client_dataset[:num_samples_to_keep][0], client_dataset[:num_samples_to_keep][1])\n",
        "        list_trainloader[idx_client] = DataLoader(new_dataset, batch_size=128)\n",
        "\n",
        "    else:\n",
        "        list_trainloader.pop(idx_client)\n",
        "\n",
        "    return list_trainloader, num_samples_to_remove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "def analyze_removal(_model, _trainloader_list):\n",
        "    remove_percentages = np.linspace(0, 1, 10)\n",
        "    trainloader_list = copy.deepcopy(_trainloader_list)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    model = copy.deepcopy(_model).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # Shuffle training datasets for each client only at the beginning\n",
        "    # (this is done to avoid fictitious determinism in the results)\n",
        "    training_datasets = [loader.dataset for loader in trainloader_list]\n",
        "    shuffled_training_datasets = []\n",
        "    for dataset in training_datasets:\n",
        "        indices = np.random.permutation(len(dataset))\n",
        "        shuffled_training_datasets.append(TensorDataset(dataset[indices][0], dataset[indices][1]))\n",
        "    shuffled_trainloader_list = [DataLoader(dataset, batch_size=128) for dataset in shuffled_training_datasets]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for remove_percentage in remove_percentages:\n",
        "\n",
        "        trainloader_list, _ = create_dataloader(party_to_be_erased, shuffled_trainloader_list, remove_percentage)\n",
        "        \n",
        "        client_dataset = ConcatDataset([loader.dataset for loader in trainloader_list])\n",
        "        loader = DataLoader(client_dataset, batch_size=128)\n",
        "\n",
        "        loss_sum = 0\n",
        "        grad_sum = torch.zeros_like(torch.cat([param.flatten() for param in model.parameters()]))\n",
        "        number_of_batches = 0\n",
        "\n",
        "        for inputs, targets in loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            # Forward pass\n",
        "            model.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            \n",
        "            # Sum quantities\n",
        "            loss_sum += loss.cpu().item()\n",
        "            grad_sum += torch.cat([param.grad.flatten() for param in model.parameters()])\n",
        "            number_of_batches += 1\n",
        "            \n",
        "        grad_norm = torch.norm(grad_sum).cpu().item() / number_of_batches\n",
        "        loss = loss_sum / number_of_batches\n",
        "\n",
        "        \n",
        "        # Store results\n",
        "        results.append({\n",
        "            'removal_percentage': remove_percentage,\n",
        "            'gradient_norm': grad_norm,\n",
        "            'loss': loss\n",
        "        })\n",
        "        \n",
        "        print(f\"Removal percentage: {remove_percentage:.2f}\")\n",
        "        print(f\"  - Number of samples: {sum([len(loader.dataset) for loader in trainloader_list])}\")\n",
        "        print(f\"  - Gradient norm: {grad_norm:.4f}\")\n",
        "        print(f\"  - Loss: {loss:.4f}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Convert results to DataFrame for easier analysis\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Create plots\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Plot gradient norm vs Removal percentage\n",
        "    axs[0].plot(results_df['removal_percentage'], results_df['gradient_norm'], 'o-')\n",
        "    axs[0].set_title('Gradient Norm vs. Removal Percentage')\n",
        "    axs[0].set_xlabel('Removal Percentage')\n",
        "    axs[0].set_ylabel('Gradient Norm')\n",
        "    axs[0].grid(True)\n",
        "\n",
        "    # Plot loss vs Removal percentage\n",
        "    axs[1].plot(results_df['removal_percentage'], results_df['loss'], 'o-')\n",
        "    axs[1].set_title('Loss vs. Removal Percentage')\n",
        "    axs[1].set_xlabel('Removal Percentage')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "#analyze_removal(saved_model, trainloader_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from backpack import backpack, extend\n",
        "from backpack.extensions import DiagHessian\n",
        "\n",
        "trainloader_list = [DataLoader(dloader.dataset, batch_size=128) for dloader in trainloader_lst]\n",
        "#trainloader_list_removed, num_removed = create_dataloader(party_to_be_erased, trainloader_list, 0.8) \n",
        "\n",
        "#Use the model if coming from the training or load if you have it downloaded\n",
        "final_model = copy.deepcopy(saved_model)\n",
        "final_model = extend(final_model)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = extend(criterion)\n",
        "\n",
        "delta = 0.0001\n",
        "\n",
        "# Create weights list\n",
        "weights_unlearned = [1] * len(trainloader_list)\n",
        "weights_unlearned[party_to_be_erased] = 1 - delta\n",
        "\n",
        "weights_unlearned=torch.tensor(weights_unlearned, dtype=torch.float32)\n",
        "\n",
        "weights_half = weights_unlearned\n",
        "weights_half[party_to_be_erased] = 1 - delta / 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute Hessians"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_diag_hessian(model, criterion, inputs, targets, device='cpu'):\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "\n",
        "    with backpack(DiagHessian()):\n",
        "        loss.backward()\n",
        "\n",
        "    diag_hessian_params = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        if hasattr(param, 'diag_h') and param.requires_grad:\n",
        "            diag_hessian_params[name] = param.diag_h.clone().detach()\n",
        "            # Cleanup to avoid leftover references\n",
        "            del param.diag_h\n",
        "\n",
        "    return diag_hessian_params\n",
        "\n",
        "\n",
        "class AccumulatedDiagHessian:\n",
        "\n",
        "    def __init__(self, model, criterion, device=None):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Will store final per-client Hessians after summing across that client's batches\n",
        "        self.client_hessians = []\n",
        "        self.total_batches = 0\n",
        "        self._computed = False\n",
        "\n",
        "    def compute_client_hessians(self, dataloader_list):\n",
        "  \n",
        "        self.model = self.model.to(self.device)\n",
        "        self.client_hessians = []\n",
        "        self.total_batches = 0\n",
        "\n",
        "        for loader_idx, loader in enumerate(dataloader_list):\n",
        "            accumulated_diag_h = {}\n",
        "            print(f\"[Hessian] Calculating diagonal Hessian for client {loader_idx}...\")\n",
        "            \n",
        "            for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "                # Compute the diag Hessian for this batch\n",
        "                diag_h = compute_diag_hessian(self.model, self.criterion, inputs, targets, device=self.device)\n",
        "\n",
        "                # Accumulate\n",
        "                for name, value in diag_h.items():\n",
        "                    if name not in accumulated_diag_h:\n",
        "                        accumulated_diag_h[name] = value\n",
        "                    else:\n",
        "                        accumulated_diag_h[name] += value\n",
        "\n",
        "                self.total_batches += 1\n",
        "\n",
        "            # Store the accumulated Hessian for this client\n",
        "            self.client_hessians.append(accumulated_diag_h)\n",
        "\n",
        "        self._computed = True\n",
        "\n",
        "    def weighted_hessian(self, weights=None):\n",
        "\n",
        "        if not self._computed:\n",
        "            raise RuntimeError(\"You must call `compute_client_hessians(...)` before requesting weights.\")\n",
        "\n",
        "        n_clients = len(self.client_hessians)\n",
        "        if weights is None:\n",
        "            weights = [1.0] * n_clients\n",
        "        if len(weights) != n_clients:\n",
        "            raise ValueError(\"Length of weights must match number of clients.\")\n",
        "\n",
        "        weighted_hessian = {}\n",
        "\n",
        "        for name in self.client_hessians[0].keys():\n",
        "            weighted_hessian[name] = sum(\n",
        "                self.client_hessians[i][name] * weights[i] for i in range(len(self.client_hessians))\n",
        "            ) / self.total_batches\n",
        "        \n",
        "        return weighted_hessian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if COMPUTE_HESSIAN:\n",
        "    hessian_calculator = AccumulatedDiagHessian(final_model, criterion)\n",
        "    hessian_calculator.compute_client_hessians(trainloader_list)\n",
        "    accumulated_diag_h = hessian_calculator.weighted_hessian()\n",
        "    accumulated_diag_h_removed = hessian_calculator.weighted_hessian(weights_unlearned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z00eqTLgZUjz"
      },
      "source": [
        "OUR METHOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fC03hVs6ZW7s"
      },
      "outputs": [],
      "source": [
        "def compute_true_info(hessian, hessian_delta, delta):\n",
        "    A_list = [torch.empty_like(p) for p in hessian.values()]\n",
        "    B_list = [torch.empty_like(p) for p in hessian.values()]\n",
        "    for i,k in enumerate(hessian.keys()): \n",
        "        print(k)\n",
        "\n",
        "        degeneracies_indices = torch.logical_or(hessian[k]==0,hessian_delta[k]==0)\n",
        "        print(f\"Number of degenaracies: {torch.sum(degeneracies_indices)}\")\n",
        "\n",
        "        ratio = hessian_delta[k]/hessian[k]\n",
        "        A=1/2 * torch.log(ratio)/delta\n",
        "        B=1/2 * (1-ratio)/delta\n",
        "\n",
        "        A[degeneracies_indices]=0\n",
        "        B[degeneracies_indices]=0\n",
        "\n",
        "        assert torch.sum(torch.isnan(A))==0, f\"NaN values in A: {torch.sum(torch.isnan(A))}\"\n",
        "        assert torch.sum(torch.isnan(B))==0, f\"NaN values in B: {torch.sum(torch.isnan(B))}\"\n",
        "        assert torch.sum(torch.isinf(A))==0, f\"Inf values in A: {torch.sum(torch.isinf(A))}\"\n",
        "        assert torch.sum(torch.isinf(B))==0, f\"Inf values in B: {torch.sum(torch.isinf(B))}\"\n",
        "\n",
        "        A_list[i]=A\n",
        "        B_list[i]=B\n",
        "\n",
        "    C = sum([torch.sum(A_list[i]+B_list[i]).item() for i in range(len(A_list))])\n",
        "\n",
        "    information_true=[(A_list[i]+B_list[i])*C + 2*torch.pow(B_list[i],2) for i in range(len(hessian.keys()))]\n",
        "\n",
        "    return information_true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_second_deriv_info(hessian, hessian_half_delta, hessian_delta, delta):\n",
        "    information = []\n",
        "    for k in hessian.keys(): \n",
        "        print(k)\n",
        "        degeneracies_indices = torch.logical_or(hessian[k]==0,hessian_delta[k]==0)\n",
        "        degeneracies_indices = torch.logical_or(degeneracies_indices, torch.pow(hessian_half_delta[k],2)==0)\n",
        "        print(f\"Number of degenaracies: {torch.sum(degeneracies_indices)}\")\n",
        "\n",
        "        A=1/2 * torch.log(hessian_delta[k]*hessian[k]/torch.pow(hessian_half_delta[k],2))\n",
        "        #plt.plot(A.cpu().flatten(), label=k+'A')\n",
        "        B=1/2 * (2*hessian_half_delta[k]/hessian[k]-hessian_delta[k]/hessian[k] -1)\n",
        "        print(np.var(B.cpu().flatten().numpy()))\n",
        "        print(np.mean(B.cpu().flatten().numpy()))\n",
        "        #plt.plot(B.cpu().flatten(), label=k+'B')\n",
        "\n",
        "        #plt.legend()\n",
        "        #plt.show()\n",
        "\n",
        "        I=-(A+B)/((delta/2)**2)\n",
        "\n",
        "        I[degeneracies_indices]=0\n",
        "\n",
        "        assert torch.sum(torch.isnan(I))==0, f\"NaN values in {k}: {torch.sum(torch.isnan(I))}\"\n",
        "        assert torch.sum(torch.isinf(I))==0, f\"Inf values in {k}: {torch.sum(torch.isinf(I))}\"\n",
        "\n",
        "        information.append(I)\n",
        "\n",
        "    return information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def delta_hessian(hessian, hessian_delta, delta):\n",
        "    delta_hessian = []\n",
        "    for k in hessian.keys():\n",
        "        delta_hessian.append(torch.abs(hessian_delta[k] - hessian[k]) / delta)\n",
        "    return delta_hessian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mgeUVILJZbnd",
        "outputId": "29f4735c-7cd4-4709-8179-b44b3728eef7"
      },
      "outputs": [],
      "source": [
        "if COMPUTE_HESSIAN:  \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    info_true = compute_true_info(accumulated_diag_h, accumulated_diag_h_removed, torch.as_tensor([delta]).to(device))\n",
        "    #info_true = compute_second_deriv_info(accumulated_diag_h, accumulated_diag_h_half, accumulated_diag_h_removed, torch.as_tensor([delta]).to(device))\n",
        "    #info_true = delta_hessian(accumulated_diag_h, accumulated_diag_h_removed, torch.as_tensor([delta]).to(device))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if COMPUTE_HESSIAN:\n",
        "    import pickle\n",
        "\n",
        "    with open('cached/info_true.pkl', 'wb') as f:\n",
        "        pickle.dump(info_true, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load hessians"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('cached/info_true.pkl', 'rb') as f:\n",
        "    info_true = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ModxW028mf5Y"
      },
      "outputs": [],
      "source": [
        "def sum_information_values(information):\n",
        "    # Initialize an empty list to store all flattened tensors\n",
        "    all_values = []\n",
        "\n",
        "    # Iterate through each parameter's information tensor\n",
        "    for tensor in information:\n",
        "        # Flatten the tensor and add to our list\n",
        "        temp=torch.nan_to_num(tensor.flatten())\n",
        "        temp = temp[torch.isinf(temp)==0]\n",
        "        temp = temp[temp!=0]\n",
        "        all_values.append(temp)\n",
        "\n",
        "    # Concatenate all tensors into one large tensor\n",
        "    combined_tensor = torch.cat(all_values)\n",
        "    print(len(combined_tensor))\n",
        "    return combined_tensor\n",
        "\n",
        "def plot_information(information):\n",
        "    combined_tensor = sum_information_values(information)\n",
        "\n",
        "    # Convert to numpy for plotting\n",
        "    values = combined_tensor.detach().cpu().numpy()\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    #Histogram\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(values, alpha=0.7, bins=50)\n",
        "    plt.title('Distribution of Information Values')\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    # Exclude outliers for the second plot (optional)\n",
        "    q1, q3 = np.percentile(values, [0, 98])\n",
        "    iqr = q3 - q1\n",
        "    # lower_bound = q1 - 1.5 * iqr\n",
        "    # upper_bound = q3 + 1.5 * iqr\n",
        "    lower_bound = q1\n",
        "    upper_bound = q3\n",
        "    filtered_values = values[(values >= lower_bound) & (values <= upper_bound)]\n",
        "    print(f\"Number of outliers: {len(values) - len(filtered_values)}\")\n",
        "\n",
        "    # Filtered histogram (without outliers)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(filtered_values, alpha=0.7, bins=30, color='green')\n",
        "    plt.title('Distribution (Outliers Removed)')\n",
        "    plt.xlabel('Value')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print some statistics\n",
        "    print(f\"Sum of all information values: {combined_tensor.sum().item():.6f}\")\n",
        "    print(f\"Mean: {combined_tensor.mean().item()}\")\n",
        "    print(f\"Min: {combined_tensor.min().item()}\")\n",
        "    print(f\"Max: {combined_tensor.max().item()}\")\n",
        "    print(f\"Total number of values: {len(values)}\")\n",
        "\n",
        "    print(f\"Sum of all information values: {filtered_values.sum().item():.6f}\")\n",
        "    print(f\"Mean: {filtered_values.mean().item()}\")\n",
        "    print(f\"Min: {filtered_values.min().item()}\")\n",
        "    print(f\"Max: {filtered_values.max().item()}\")\n",
        "    print(f\"Total number of values: {len(filtered_values)}\")\n",
        "\n",
        "    return combined_tensor.sum().item(), filtered_values.sum().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "F4R6HHhMmlt5",
        "outputId": "2c8b6c11-1b48-4702-86be-64b04f0bb913"
      },
      "outputs": [],
      "source": [
        "plot_information(info_true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "import seaborn as sns\n",
        "\n",
        "# create validation routine\n",
        "def validate(net, dl, n_classes, device):\n",
        "    # create metric objects\n",
        "    tm_acc = torchmetrics.Accuracy(task='multiclass', num_classes=n_classes, average= 'macro', top_k=1)\n",
        "    tm_con = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=n_classes)\n",
        "    # move metric to device\n",
        "    net.to(device)\n",
        "    tm_acc.to(device)\n",
        "    tm_con.to(device)\n",
        "    # set network in eval mode\n",
        "    net.eval()\n",
        "    # at the end of epoch, validate model\n",
        "    for loader_idx, loader in enumerate(dl):\n",
        "        for inputs, targets in loader:\n",
        "        \n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            # remove singleton dimension\n",
        "            targets = targets.squeeze()\n",
        "            # get output\n",
        "            with torch.no_grad():\n",
        "                # perform prediction\n",
        "                logits = net(inputs)\n",
        "            # update metrics\n",
        "            _, predicted = torch.max(logits.data, 1)\n",
        "            tm_acc.update(predicted, targets)\n",
        "            tm_con.update(predicted, targets)\n",
        "\n",
        "    # at the end, compute metric\n",
        "    acc = tm_acc.compute()\n",
        "    con = tm_con.compute()\n",
        "    # set network in training mode\n",
        "    \n",
        "    return acc, con\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(conf_mat):\n",
        "    cm = sns.light_palette(\"blue\", as_cmap=True)\n",
        "    x=pd.DataFrame(conf_mat.cpu())\n",
        "    x=x.style.background_gradient(cmap=cm)\n",
        "    display(x)\n",
        "\n",
        "\n",
        "# Compute accuracy for each client\n",
        "def compute_accuracy(model, testloader):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = model.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in testloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "def compute_accuracy_per_client(model, testloader_list):\n",
        "    for i, testloader in enumerate(testloader_list):\n",
        "        acc = compute_accuracy(model, testloader)\n",
        "        print(f\"Accuracy for class {i}: {acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "info_true=[p.cpu() for p in info_true]\n",
        "infocat = torch.cat([p.flatten() for p in info_true])\n",
        "s_infocat = np.sort(torch.nan_to_num(infocat))[::-1]\n",
        "\n",
        "s_infolayers = [np.sort(p.cpu().flatten())[::-1] for p in info_true]\n",
        "\n",
        "plt.plot(s_infocat)\n",
        "plt.title('Sorted Information Values for All Parameters')\n",
        "plt.show()\n",
        "\n",
        "# from kneed import KneeLocator\n",
        "# start = [0, 0, 0, 0, 0, 0, 0, 0]\n",
        "# end = [-1, -1, -10000, -30, -1, -1, -1, -1]\n",
        "# step = [1, 1, 1, 1, 100, 1, 1, 1]\n",
        "# auto_thresholds = []\n",
        "# for i in range(len(s_infolayers)):\n",
        "#     kneedle = KneeLocator(range(len(s_infolayers[i][start[i]:end[i]:step[i]])), s_infolayers[i][start[i]:end[i]:step[i]], curve='convex', direction='decreasing', online=True)\n",
        "#     auto_thresholds.append(start[i]+kneedle.knee*step[i])\n",
        "#     print(f'Layer {i} knee:', auto_thresholds[i])\n",
        "\n",
        "auto_percentage = 12\n",
        "custom_percentages = [None, None, None, None, None, None, None, None]\n",
        "\n",
        "percentages = [auto_percentage if custom_percentages[i] is None else custom_percentages[i] for i in range(len(custom_percentages))]\n",
        "\n",
        "auto_thresholds = [len(s_infolayers[i]) // 100 * percentages[i] for i in range(len(s_infolayers))]\n",
        "\n",
        "custom_thresholds = [None, None, None, None, None, None, None, None]\n",
        "\n",
        "thresholds = [auto_thresholds[i] if custom_thresholds[i] is None else custom_thresholds[i] for i in range(len(custom_thresholds))]\n",
        "\n",
        "for i in range(len(s_infolayers)):\n",
        "    fig, axs = plt.subplots(1, 1, figsize=(14, 5))\n",
        "    axs.plot(s_infolayers[i])\n",
        "    axs.axvline(auto_thresholds[i], color='red', linestyle='--', label='Auto threshold')\n",
        "    axs.axvline(thresholds[i], color='green', linestyle='--', label='Custom threshold')\n",
        "    axs.legend()\n",
        "    axs.set_title(f'Thresholds for layer {i}')\n",
        "    fig.show()\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parameters reset unlearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "thresholds_values = [p[thresholds[i]] for i,p in enumerate(s_infolayers)]\n",
        "retrain_param_indices = []\n",
        "for i, p in enumerate(info_true):\n",
        "    if custom_thresholds[i] != 0:\n",
        "        indices = torch.argwhere(p > thresholds_values[i])\n",
        "        retrain_param_indices.append(indices)\n",
        "    else:\n",
        "        retrain_param_indices.append(torch.empty(size=[0 for _ in range(p.dim())]))\n",
        "\n",
        "model_reset = copy.deepcopy(saved_model).cpu()\n",
        "model_null = FLNet2()\n",
        "\n",
        "original_parameters = model_reset.state_dict()\n",
        "null_parameters = model_null.state_dict()\n",
        "\n",
        "reset_parameters = {}\n",
        "for i, (name, p) in enumerate(model_reset.named_parameters()):\n",
        "    new_p = original_parameters[name].clone()\n",
        "    null_p = null_parameters[name].clone()\n",
        "    #new_p[tuple(retrain_param_indices[i].t())] = null_p[tuple(retrain_param_indices[i].t())]\n",
        "    new_p[tuple(retrain_param_indices[i].t())] = 0\n",
        "    reset_parameters[name] = new_p\n",
        "\n",
        "model_reset.load_state_dict(reset_parameters)\n",
        "\n",
        "print(\"Accuracy before resetting:\")\n",
        "compute_accuracy_per_client(saved_model, trainloader_class_list)\n",
        "print(\"Accuracy after resetting:\")\n",
        "compute_accuracy_per_client(model_reset, trainloader_class_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Confusion matrix before resetting:\")\n",
        "acc, conf_mat = validate(saved_model, trainloader_class_list, 10, device)\n",
        "plot_confusion_matrix(conf_mat)\n",
        "print(\"Confusion matrix after resetting:\")\n",
        "acc, conf_mat = validate(model_reset, trainloader_class_list, 10, device)\n",
        "plot_confusion_matrix(conf_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_info_stats(information):\n",
        "    \"\"\"\n",
        "    Compute statistics for the information values.\n",
        "    \"\"\"\n",
        "    # Flatten the information values and convert to numpy\n",
        "    layers_total_information = [torch.sum(p) for p in information]\n",
        "\n",
        "    for i, info in enumerate(layers_total_information):\n",
        "        print(f\"Layer {i} - Total Information: {info:.4f}\")\n",
        "    \n",
        "    print(f\"Total Information: {sum(layers_total_information):.4f}\")\n",
        "\n",
        "print(\"Information before resetting:\")\n",
        "print_info_stats(info_true)\n",
        "\n",
        "reset_info_true = copy.deepcopy(info_true)\n",
        "for i in range(len(reset_info_true)):\n",
        "    reset_info_true[i][tuple(retrain_param_indices[i].t())] = 0\n",
        "print(\"Information after resetting:\")\n",
        "print_info_stats(reset_info_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class UnlearnNet(nn.Module):\n",
        "    \"\"\"\n",
        "    A module that wraps an existing model and selectively retrains individual \n",
        "    scalar elements (indices) of its parameters while keeping the rest fixed.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_model, indices_to_retrain):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            base_model (nn.Module): The original model whose parameters \n",
        "                                    we want to partially retrain.\n",
        "            indices_to_retrain (List[torch.Tensor]): For each parameter of \n",
        "                                    'base_model', a tensor of indices indicating \n",
        "                                    which scalar values should be retrained.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # We store the base model inside a dictionary to allow\n",
        "        # functional calls later without overshadowing state_dict keys.\n",
        "        self.inner_model = {\"model\": base_model}\n",
        "\n",
        "        # Move any index tensors to CPU and store them.\n",
        "        self.indices_to_retrain = [idx.cpu() for idx in indices_to_retrain]\n",
        "\n",
        "        # Create a copy of the base model's parameters as buffers, where\n",
        "        # we zero out the positions that will be retrained.\n",
        "        base_params = {}\n",
        "        for i, (param_name, param) in enumerate(base_model.named_parameters()):\n",
        "            # Detach a clone of the original parameter\n",
        "            cloned_param = param.clone().detach()\n",
        "            # Zero-out the entries we plan to retrain\n",
        "            if len(self.indices_to_retrain[i]) > 0:\n",
        "                cloned_param[tuple(self.indices_to_retrain[i].t())] = 0\n",
        "            base_params[param_name] = cloned_param\n",
        "\n",
        "        # Register these base parameters as buffers so they are not optimized\n",
        "        for param_name, buf in base_params.items():\n",
        "            buf_name = param_name.replace(\".\", \"_\")\n",
        "            self.register_buffer(f\"base_{buf_name}\", buf)\n",
        "\n",
        "        # Create the new learnable parameters for only the chosen indices\n",
        "        retrain_params_dict = {}\n",
        "        for i, (param_name, param) in enumerate(base_model.named_parameters()):\n",
        "            if len(self.indices_to_retrain[i]) == 0:\n",
        "                continue\n",
        "            # We create a 1D tensor (one entry per retrained element)\n",
        "            key = param_name.replace(\".\", \"_\")\n",
        "            retrain_params_dict[key] = nn.Parameter(\n",
        "                torch.zeros(len(self.indices_to_retrain[i]))\n",
        "            )\n",
        "        self.retrain_params = nn.ParameterDict(retrain_params_dict)\n",
        "\n",
        "        # Build sparse masks to apply the learnable values at the correct indices\n",
        "        sparse_masks = {}\n",
        "        for i, (param_name, param) in enumerate(base_model.named_parameters()):\n",
        "            if len(self.indices_to_retrain[i]) == 0:\n",
        "                continue\n",
        "            # 'retrain_indices' has shape (k, n_dims). Add a final dim to index positions in the retrain-param vector.\n",
        "            retrain_indices = indices_to_retrain[i]\n",
        "            k = retrain_indices.size(0)\n",
        "\n",
        "            # Create an index column [0..k-1], then concatenate it with 'retrain_indices'.\n",
        "            row_idx = torch.arange(k).unsqueeze(1)\n",
        "            final_idx_matrix = torch.cat([retrain_indices, row_idx], dim=1)\n",
        "\n",
        "            # A sparse_coo_tensor expects indices with shape (ndim, nnz). Transpose to (n_dims+1, k).\n",
        "            indices_for_sparse = final_idx_matrix.t().contiguous()\n",
        "\n",
        "            # Append k as the final dimension so each retrained element indexes differently.\n",
        "            mask_shape = tuple(param.size()) + (k,)\n",
        "\n",
        "            # Build the sparse mask with 1.0 at the retrained indices.\n",
        "            key = f\"mask_{param_name.replace('.', '_')}\"\n",
        "            sparse_masks[key] = torch.sparse_coo_tensor(\n",
        "                indices_for_sparse,\n",
        "                torch.ones(k, dtype=torch.float32),\n",
        "                size=mask_shape\n",
        "            )\n",
        "        \n",
        "        # Register these sparse masks as buffers\n",
        "        for mask_name, mask in sparse_masks.items():\n",
        "            self.register_buffer(mask_name, mask.coalesce())\n",
        "\n",
        "    def contract_last_dim_with_vector(self, sp_tensor: torch.Tensor, vec: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Contract the last dimension of a sparse tensor (shape [..., N]) with\n",
        "        a dense vector of shape (N,), returning a sparse tensor of shape [...].\n",
        "\n",
        "        This effectively applies elementwise multiplication with 'vec'\n",
        "        across the last dimension of 'sp_tensor'.\n",
        "        \"\"\"\n",
        "\n",
        "        # Extract indices (shape [ndim, nnz]) and values (shape [nnz])\n",
        "        indices = sp_tensor.indices()\n",
        "        values = sp_tensor.values()\n",
        "\n",
        "        # Multiply each sparse value by the corresponding element in 'vec'\n",
        "        # indices[-1] indicates which element in 'vec' to use per sparse entry\n",
        "        new_values = values * vec[indices[-1]]\n",
        "\n",
        "        # Create a new sparse_coo_tensor with one fewer dimension\n",
        "        new_shape = sp_tensor.shape[:-1]\n",
        "        new_indices = indices[:-1, :]  # drop the last dimension index row\n",
        "\n",
        "        result_tensor = torch.sparse_coo_tensor(\n",
        "            new_indices,\n",
        "            new_values,\n",
        "            size=new_shape,\n",
        "            dtype=sp_tensor.dtype,\n",
        "            device=sp_tensor.device\n",
        "        )\n",
        "\n",
        "        return result_tensor\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass using a functional call to the base model. We reconstruct \n",
        "        final parameters by adding the base buffers and the contracted retrain \n",
        "        parameters at the relevant indices.\n",
        "        \"\"\"\n",
        "        model = self.inner_model[\"model\"]\n",
        "        current_state = self.state_dict()\n",
        "\n",
        "        # Rebuild parameter dict from buffers (base params)\n",
        "        final_params = {}\n",
        "        for param_name in model.state_dict().keys():\n",
        "            buf_name = param_name.replace(\".\", \"_\")\n",
        "            final_params[param_name] = current_state[f\"base_{buf_name}\"]\n",
        "\n",
        "        # Add in the learnable values at specified indices\n",
        "        for key, param_vector in self.retrain_params.items():\n",
        "            mask_key = f\"mask_{key}\"\n",
        "            base_key = f\"base_{key}\"\n",
        "            original_param_name = key.replace(\"_\", \".\")\n",
        "\n",
        "            # Convert sparse mask to shape that can be added to base param\n",
        "            sparse_update = self.contract_last_dim_with_vector(\n",
        "                current_state[mask_key], param_vector\n",
        "            )\n",
        "\n",
        "            # Add the sparse update to the base buffer\n",
        "            final_params[original_param_name] = (\n",
        "                current_state[base_key] + sparse_update\n",
        "            )\n",
        "\n",
        "        # Perform a functional forward pass with the reconstructed parameters\n",
        "        return torch.func.functional_call(model, final_params, x)\n",
        "    \n",
        "    def get_retrained_params(self):\n",
        "        \"\"\"\n",
        "        Returns the retrained parameters of the model.\n",
        "        \"\"\"\n",
        "        model = self.inner_model[\"model\"]\n",
        "        current_state = self.state_dict()\n",
        "\n",
        "        # Rebuild parameter dict from buffers (base params)\n",
        "        final_params = {}\n",
        "        for param_name in model.state_dict().keys():\n",
        "            buf_name = param_name.replace(\".\", \"_\")\n",
        "            final_params[param_name] = current_state[f\"base_{buf_name}\"]\n",
        "\n",
        "        # Add in the learnable values at specified indices\n",
        "        for key, param_vector in self.retrain_params.items():\n",
        "            mask_key = f\"mask_{key}\"\n",
        "            base_key = f\"base_{key}\"\n",
        "            original_param_name = key.replace(\"_\", \".\")\n",
        "\n",
        "            # Convert sparse mask to shape that can be added to base param\n",
        "            sparse_update = self.contract_last_dim_with_vector(\n",
        "                current_state[mask_key], param_vector\n",
        "            )\n",
        "\n",
        "            # Add the sparse update to the base buffer\n",
        "            final_params[original_param_name] = (\n",
        "                current_state[base_key] + sparse_update\n",
        "            )\n",
        "        \n",
        "        detached_params = {}\n",
        "        for key, value in final_params.items():\n",
        "            detached_params[key] = value.cpu().detach()\n",
        "        return detached_params\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert RETRAIN\n",
        "#Test\n",
        "unlearn_model = UnlearnNet(model_reset, retrain_param_indices)\n",
        "\n",
        "print(\"Unlearn model parameters:\")\n",
        "for name , param in unlearn_model.named_parameters():\n",
        "    print(name, param.shape)\n",
        "\n",
        "# print(\"Accuracy (reset before retrain)\")\n",
        "# compute_accuracy_per_client(unlearn_model, trainloader_class_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_of_repeats = 1\n",
        "num_fl_rounds = 1\n",
        "\n",
        "#fusion_types = ['FedAvg','Retrain']\n",
        "fusion_types = ['FedAvg']\n",
        "fusion_types_unlearn = ['Retrain', 'Unlearn']\n",
        "\n",
        "num_updates_in_epoch = None\n",
        "num_local_epochs = 2\n",
        "\n",
        "dist_Retrain = {}\n",
        "loss_fed = {}\n",
        "grad_fed = {}\n",
        "clean_accuracy = {}\n",
        "pois_accuracy = {}\n",
        "for fusion_key in fusion_types:\n",
        "    loss_fed[fusion_key] = np.zeros(num_fl_rounds)\n",
        "    grad_fed[fusion_key] = np.zeros(num_fl_rounds)\n",
        "    clean_accuracy[fusion_key] = np.zeros(num_fl_rounds)\n",
        "    pois_accuracy[fusion_key] = np.zeros(num_fl_rounds)\n",
        "    if fusion_key != 'Retrain':\n",
        "        dist_Retrain[fusion_key] = np.zeros(num_fl_rounds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device == 'cuda':\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "party_models_dict = {}\n",
        "initial_model = unlearn_model\n",
        "model_dict = {}\n",
        "parties = list(range(5))\n",
        "del parties[party_to_be_erased]\n",
        "\n",
        "for fusion_key in fusion_types:\n",
        "    model_dict[fusion_key] = copy.deepcopy(initial_model.state_dict())\n",
        "\n",
        "for round_num in range(num_fl_rounds):\n",
        "    local_training = LocalTraining(num_updates_in_epoch=num_updates_in_epoch, num_local_epochs=num_local_epochs)\n",
        "\n",
        "    for fusion_key in fusion_types:\n",
        "        fusion = FL_round_fusion_selection(num_parties=len(parties), fusion_key=fusion_key)\n",
        "\n",
        "        current_model_state_dict = copy.deepcopy(model_dict[fusion_key])\n",
        "        model = copy.deepcopy(initial_model)\n",
        "        model.load_state_dict(current_model_state_dict)\n",
        "\n",
        "        ##################### Local Training Round #############################\n",
        "        party_models = []\n",
        "        party_losses = []\n",
        "        party_grad   = []        \n",
        "        for party_id in parties:\n",
        "\n",
        "            if fusion_key == 'Retrain':\n",
        "                break\n",
        "            else:\n",
        "                print(f\"Training party {party_id}\")\n",
        "                model = UnlearnNet(model_reset, retrain_param_indices)\n",
        "                model.load_state_dict(current_model_state_dict)\n",
        "                model.to(device)\n",
        "                model_update, party_loss = local_training.train(model=model,\n",
        "                                            trainloader=trainloader_lst[party_id],\n",
        "                                            device = device,\n",
        "                                            criterion=None, opt=None)\n",
        "                model_update_copy = UnlearnNet(model_reset, retrain_param_indices)\n",
        "                model_update_copy.load_state_dict(model_update.state_dict())\n",
        "                model_update_copy.to(\"cpu\")\n",
        "                party_models.append(model_update_copy)\n",
        "                party_losses.append(party_loss)\n",
        "\n",
        "            grad_norm = 0.0\n",
        "            for name,param in model_update.named_parameters():\n",
        "                if param.grad is not None:\n",
        "                    grad_norm += torch.norm(param.grad).cpu().item()\n",
        "                    #print(f\"Gradient norm for {name}: {grad_norm}\")\n",
        "                else:\n",
        "                    #print(f\"Gradient is None for {name}\")\n",
        "                    pass\n",
        "        \n",
        "            party_grad.append(grad_norm)   \n",
        "        \n",
        "        grad_fed[fusion_key][round_num] += (np.mean(party_grad)/num_of_repeats) \n",
        "\n",
        "        loss_fed[fusion_key][round_num] += (np.mean(party_losses)/num_of_repeats)\n",
        "        ######################################################################\n",
        "\n",
        "        current_model_state_dict = fusion.fusion_algo(party_models=party_models, current_model=model)\n",
        "\n",
        "        eval_model = copy.deepcopy(initial_model).to(\"cpu\")\n",
        "        eval_model.load_state_dict(current_model_state_dict)\n",
        "        clean_acc = Utils.evaluate(testloader, eval_model)\n",
        "        clean_accuracy[fusion_key][round_num] = clean_acc\n",
        "        print(f'Global Clean Accuracy {fusion_key}, round {round_num} = {clean_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Accuracy after retrain\")\n",
        "compute_accuracy_per_client(eval_model, trainloader_class_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Confusion matrix after retrain:\")\n",
        "acc, conf_mat = validate(eval_model, trainloader_class_list, 10, \"cuda\")\n",
        "plot_confusion_matrix(conf_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainloader_list = [DataLoader(dloader.dataset, batch_size=128) for dloader in trainloader_lst]\n",
        "#trainloader_list_removed, num_removed = create_dataloader(party_to_be_erased, trainloader_list, 0.8) \n",
        "\n",
        "\n",
        "final_model = FLNet2()\n",
        "unlearned_params = eval_model.get_retrained_params()\n",
        "\n",
        "\n",
        "final_model.load_state_dict(unlearned_params)\n",
        "final_model = extend(final_model)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = extend(criterion)\n",
        "\n",
        "delta = 0.01\n",
        "\n",
        "# Create weights list\n",
        "weights_unlearned = [1] * len(trainloader_list)\n",
        "weights_unlearned[party_to_be_erased] = 0\n",
        "weights_delta = weights_unlearned.copy()\n",
        "weights_delta[party_to_be_erased] = delta\n",
        "\n",
        "weights_unlearned=torch.tensor(weights_unlearned, dtype=torch.float32)\n",
        "weights_delta=torch.tensor(weights_delta, dtype=torch.float32)\n",
        "\n",
        "accumulated_diag_h_retrain = calculate_accumulated_diag_hessian(trainloader_list, final_model, criterion, weights_unlearned)\n",
        "accumulated_diag_h_removed_retrain = calculate_accumulated_diag_hessian(trainloader_list, final_model, criterion, weights_delta)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "info_true = compute_true_info(accumulated_diag_h_retrain, accumulated_diag_h_removed_retrain, torch.as_tensor([delta]).to(device))\n",
        "\n",
        "plot_information(info_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client0 = torch.load(\"client0\")\n",
        "client1 = torch.load(\"client1\")\n",
        "client2 = torch.load(\"client2\")\n",
        "client3 = torch.load(\"client3\")\n",
        "client4 = torch.load(\"client4\")\n",
        "\n",
        "# For NumPy arrays\n",
        "import numpy as np\n",
        "\n",
        "def count_equal_arrays(list1, list2):\n",
        "    equal_count = 0\n",
        "    min_length = min(len(list1), len(list2))\n",
        "    \n",
        "    for i in range(min_length):\n",
        "        if np.array_equal(list1[i], list2[i]):\n",
        "            print(list1[i])\n",
        "            equal_count += 1\n",
        "    \n",
        "    return equal_count\n",
        "\n",
        "count_equal_arrays(client4[6], client4[6])\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def tensor_list_distance(list1, list2, metric='euclidean'):\n",
        "    \"\"\"\n",
        "    Compute various distance metrics between two lists of tensors.\n",
        "    \n",
        "    Args:\n",
        "        list1: First list of tensors\n",
        "        list2: Second list of tensors\n",
        "        metric: Distance metric to use ('euclidean', 'manhattan', 'cosine', 'mean_squared', 'element_diff')\n",
        "        \n",
        "    Returns:\n",
        "        float: The computed distance between the two tensor lists\n",
        "    \"\"\"\n",
        "    # Make sure we only compare up to the length of the shorter list\n",
        "    min_length = min(len(list1), len(list2))\n",
        "    \n",
        "    if min_length == 0:\n",
        "        raise ValueError(\"At least one of the lists is empty\")\n",
        "        \n",
        "    # Initialize distance\n",
        "    distances = []\n",
        "    \n",
        "    # Compute distance for each pair of tensors\n",
        "    for i in range(min_length):\n",
        "        tensor1 = list1[i].float()  # Ensure tensors are float type\n",
        "        tensor2 = list2[i].float()\n",
        "        \n",
        "        if metric == 'euclidean':\n",
        "            # Euclidean distance\n",
        "            dist = torch.sqrt(torch.sum((tensor1 - tensor2) ** 2)).item()\n",
        "            distances.append(dist)\n",
        "            \n",
        "        elif metric == 'manhattan':\n",
        "            # Manhattan (L1) distance\n",
        "            dist = torch.sum(torch.abs(tensor1 - tensor2)).item()\n",
        "            distances.append(dist)\n",
        "            \n",
        "        elif metric == 'cosine':\n",
        "            # Cosine distance (1 - cosine similarity)\n",
        "            dot_product = torch.sum(tensor1 * tensor2)\n",
        "            norm1 = torch.sqrt(torch.sum(tensor1 ** 2))\n",
        "            norm2 = torch.sqrt(torch.sum(tensor2 ** 2))\n",
        "            \n",
        "            # Avoid division by zero\n",
        "            if norm1 == 0 or norm2 == 0:\n",
        "                dist = 1.0  # Maximum distance\n",
        "            else:\n",
        "                cosine_sim = dot_product / (norm1 * norm2)\n",
        "                # Clip to handle floating point errors\n",
        "                cosine_sim = torch.clamp(cosine_sim, -1.0, 1.0)\n",
        "                dist = 1.0 - cosine_sim.item()\n",
        "                \n",
        "            distances.append(dist)\n",
        "            \n",
        "        elif metric == 'mean_squared':\n",
        "            # Mean squared error\n",
        "            dist = torch.mean((tensor1 - tensor2) ** 2).item()\n",
        "            distances.append(dist)\n",
        "            \n",
        "        elif metric == 'element_diff':\n",
        "            # Count of different elements\n",
        "            diff_count = torch.sum(tensor1 != tensor2).item()\n",
        "            distances.append(diff_count)\n",
        "            \n",
        "        else:\n",
        "            raise ValueError(f\"Unknown distance metric: {metric}\")\n",
        "    \n",
        "    # Compute average distance across all tensor pairs\n",
        "    avg_distance = np.mean(distances)\n",
        "    \n",
        "    # Calculate additional statistics\n",
        "    stats = {\n",
        "        \"mean\": avg_distance,\n",
        "        \"median\": np.median(distances),\n",
        "        \"min\": np.min(distances),\n",
        "        \"max\": np.max(distances),\n",
        "        \"std\": np.std(distances),\n",
        "        \"distances\": distances  # List of all pairwise distances\n",
        "    }\n",
        "    \n",
        "    return stats\n",
        "\n",
        "    \n",
        "# Compute distances using different metrics\n",
        "for metric in ['euclidean', 'element_diff']:\n",
        "    result = tensor_list_distance(client0[4], client1[4], metric=metric)\n",
        "    print(f\"\\n{metric.upper()} Distance:\")\n",
        "    print(f\"Mean: {result['mean']:.6f}\")\n",
        "    print(f\"Median: {result['median']:.6f}\")\n",
        "    print(f\"Min: {result['min']:.6f}\")\n",
        "    print(f\"Max: {result['max']:.6f}\")\n",
        "    print(f\"Std: {result['std']:.6f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9GexoT5UbGQl"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
