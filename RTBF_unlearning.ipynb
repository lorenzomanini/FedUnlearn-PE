{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh5fRZAI0cpa"
      },
      "outputs": [],
      "source": [
        "from fisherunlearn import compute_client_information, find_informative_params, reset_parameters, mia_attack\n",
        "from fisherunlearn import UnlearnNet\n",
        "\n",
        "import fisherunlearn\n",
        "\n",
        "import copy\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from backpack import extend, backpack\n",
        "from backpack.extensions import DiagHessian, DiagGGNMC, DiagGGNExact\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import logging\n",
        "import functools\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.models import resnet18\n",
        "import seaborn as sns\n",
        "\n",
        "import torchmetrics\n",
        "from torch.multiprocessing import Pool, Queue\n",
        "torch.multiprocessing.set_start_method('spawn', force=True)\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from tqdm.contrib.logging import logging_redirect_tqdm\n",
        "\n",
        "from typing import TypedDict, Literal\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN = True"
      ],
      "metadata": {
        "id": "1GI0_rVVQSdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "INFO_BATCH_SIZE = 5"
      ],
      "metadata": {
        "id": "plde0Yk80m9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create validation routine\n",
        "def validate(net, dl, n_classes, device):\n",
        "    # create metric objects\n",
        "    tm_acc = torchmetrics.Accuracy(task='multiclass', num_classes=n_classes, average='macro', top_k=1)\n",
        "    tm_con = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=n_classes)\n",
        "    # move metric to device\n",
        "    tm_acc.to(device)\n",
        "    tm_con.to(device)\n",
        "    # set network in eval mode\n",
        "    net.eval()\n",
        "    # at the end of epoch, validate model\n",
        "    for inp, gt in dl:\n",
        "        # move batch to gpu\n",
        "        inp = inp.to(device).float()\n",
        "        gt = gt.to(device)\n",
        "        # remove singleton dimension if it exists\n",
        "        if gt.ndim > 1:\n",
        "            gt = gt.squeeze()\n",
        "        # get output\n",
        "        with torch.no_grad():\n",
        "            # perform prediction\n",
        "            logits = net(inp)\n",
        "\n",
        "        # update metrics with the raw logits\n",
        "        tm_acc.update(logits, gt)\n",
        "        tm_con.update(logits, gt)\n",
        "\n",
        "    # at the end, compute metric\n",
        "    acc = tm_acc.compute()\n",
        "    con = tm_con.compute()\n",
        "    # return score\n",
        "    return acc, con"
      ],
      "metadata": {
        "id": "W57LbPZZGIPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the data\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, csv):\n",
        "        # read the csv file\n",
        "        self.df = pd.read_csv(csv, sep=',')\n",
        "        # self.df = self.df.dropna(axis=0)\n",
        "        # save cols\n",
        "        self.output_cols = ['outcome']\n",
        "        self.input_cols = list(set(self.df.columns)-set(self.output_cols))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        # here i will return the number of samples in the dataset\n",
        "        return len(self.df)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # here i will load the file in position idx\n",
        "        cur_sample = self.df.iloc[idx]\n",
        "        # split in input / ground-truth\n",
        "        cur_sample_x = cur_sample[self.input_cols]\n",
        "        cur_sample_y = cur_sample[self.output_cols]\n",
        "        # convert to torch format\n",
        "        cur_sample_x = torch.tensor(cur_sample_x.tolist())\n",
        "        cur_sample_y = torch.tensor(cur_sample_y.tolist())\n",
        "        # remove dimension on gt\n",
        "        cur_sample_y = cur_sample_y.squeeze()\n",
        "        # convert to int\n",
        "        cur_sample_y = cur_sample_y.long()\n",
        "        # return values\n",
        "        return cur_sample_x, cur_sample_y\n",
        "\n",
        "# create train and validation datasets\n",
        "train_ds = Dataset('Brcancer/train.csv')\n",
        "test_ds =  Dataset('Brcancer/test.csv')\n",
        "\n",
        "eligible = [i for i, sample in enumerate(train_ds) if sample[\"age\"] <= 40]\n",
        "\n",
        "# --- Option A: pick exactly 1 ---\n",
        "random.seed(42)  # for reproducibility\n",
        "indices_to_forget = [random.choice(eligible)] if eligible else []\n",
        "\n",
        "# --- Option B: pick a fixed count k ---\n",
        "k = 10  # choose how many to remove\n",
        "#indices_to_forget = random.sample(eligible, k=min(k, len(eligible)))\n",
        "\n",
        "# --- Option C: pick a percentage p% of eligible ---\n",
        "p = 30  # e.g., 30%\n",
        "n = math.floor(len(eligible) * (p / 100.0))\n",
        "#indices_to_forget = random.sample(eligible, k=n) if n > 0 else []\n",
        "\n",
        "# Get the indices for the data we want to keep.\n",
        "full_train_indices = list(range(len(train_ds)))\n",
        "indices_to_retain = list(set(full_train_indices) - set(indices_to_forget))\n",
        "\n",
        "# Create the two datasets using torch.utils.data.Subset\n",
        "forget_set = Subset(train_ds, indices_to_forget)\n",
        "retain_set = Subset(train_ds, indices_to_retain)\n",
        "\n",
        "datasets_for_unlearning = [retain_set, forget_set]\n",
        "\n",
        "print(f\"Total training samples: {len(train_ds)}\")\n",
        "print(f\"Number of samples to retain: {len(retain_set)}\")\n",
        "print(f\"Number of samples to forget: {len(forget_set)}\")"
      ],
      "metadata": {
        "id": "6fdAXJEG34oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_inputs = 12\n",
        "n_classes = 3\n",
        "\n",
        "class Net(nn.Sequential):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__(\n",
        "            nn.Linear(12, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 3)\n",
        "        )"
      ],
      "metadata": {
        "id": "PZNxfTvW3bH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adam_trainer(model, loss_fn, dataloader, epochs):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.train()\n",
        "\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Using Adam optimizer\n",
        "\n",
        "    for epoch in tqdm(range(epochs), desc=\"Training (Adam)\", unit=\"epoch\", leave=False):\n",
        "        epoch_loss = 0.0\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device).float(), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        logging.info(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(dataloader):.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    return model.cpu()"
      ],
      "metadata": {
        "id": "zmN_MOGbP7TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "batch_size = 5\n",
        "\n",
        "if TRAIN == True:\n",
        "  train_dl = torch.utils.data.DataLoader(\n",
        "    train_ds,\n",
        "    batch_size = batch_size,\n",
        "    drop_last = True,\n",
        "    shuffle = True\n",
        "    )\n",
        "  trained_model = adam_trainer(Net(), criterion, train_dl, epochs=300)\n",
        "  print(\"Successfully trained the model.\")\n",
        "\n",
        "else:\n",
        "  experiment_name = 'test'\n",
        "\n",
        "  trained_model = Net()\n",
        "\n",
        "  checkpoint = torch.load(experiment_name + '_best.pth', map_location=torch.device(DEVICE))\n",
        "  trained_model.load_state_dict(checkpoint['net'])\n",
        "  trained_model.to(DEVICE)\n",
        "  print(\"Successfully loaded the trained model.\")"
      ],
      "metadata": {
        "id": "x582rdMJQPXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create train dataloader\n",
        "retain_loader = torch.utils.data.DataLoader(\n",
        "    retain_set,\n",
        "    batch_size = batch_size,\n",
        "    drop_last = True,\n",
        "    shuffle = False\n",
        "    )\n",
        "\n",
        "forget_loader = torch.utils.data.DataLoader(\n",
        "    forget_set,\n",
        "    batch_size = batch_size,\n",
        "    drop_last = True,\n",
        "    shuffle = False\n",
        "    )\n",
        "\n",
        "test_dl = torch.utils.data.DataLoader(\n",
        "    test_ds,\n",
        "    batch_size = 1,\n",
        "    drop_last = False,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "acc_original_on_retain, _ = validate(trained_model, retain_loader, n_classes, DEVICE)\n",
        "acc_original_on_forget, _ = validate(trained_model, forget_loader, n_classes, DEVICE)\n",
        "acc_original_on_test, _ = validate(trained_model, test_dl, n_classes, DEVICE)\n",
        "\n",
        "baseline_results = {\n",
        "    \"Unlearning %\": \"0% (Original Model)\",\n",
        "    \"Forget Set Acc\": f\"{acc_original_on_forget.item():.4f}\",\n",
        "    \"Retain Set Acc\": f\"{acc_original_on_retain.item():.4f}\",\n",
        "    \"Test Set Acc\": f\"{acc_original_on_test.item():.4f}\",\n",
        "    \"Reset Params\": 0\n",
        "}\n"
      ],
      "metadata": {
        "id": "cmHbNTgQGWUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_idx_to_remove = 1\n",
        "\n",
        "unlearning_info = compute_client_information(\n",
        "    client_idx=client_idx_to_remove,\n",
        "    model=trained_model,\n",
        "    criterion=criterion,\n",
        "    datasets_list=datasets_for_unlearning,\n",
        "    method='diag_ggn'\n",
        ")\n",
        "\n",
        "unlearning_method = \"information\" #\"parameter\"\n",
        "\n",
        "unlearning_percentage = 40\n",
        "\n",
        "whitelist = None\n",
        "blacklist = None\n",
        "\n",
        "test_params_dict = {\n",
        "    'unlearning_method': unlearning_method,\n",
        "    'unlearning_percentage': unlearning_percentage,\n",
        "    'whitelist': whitelist,\n",
        "    'blacklist': blacklist\n",
        "}\n",
        "\n",
        "def run_tests(test_params_dict, trained_model, DEVICE):\n",
        "\n",
        "  unlearning_method = test_params_dict['unlearning_method']\n",
        "  unlearning_percentage = test_params_dict['unlearning_percentage']\n",
        "  whitelist = test_params_dict.get('whitelist', None)\n",
        "  blacklist = test_params_dict.get('blacklist', None)\n",
        "\n",
        "  informative_params = find_informative_params(unlearning_info, unlearning_method, unlearning_percentage, whitelist, blacklist)\n",
        "  total_individual_reset_params = 0\n",
        "  for name, indices_tensor in informative_params.items():\n",
        "            if indices_tensor is not None and indices_tensor.numel() > 0:\n",
        "                 total_individual_reset_params += indices_tensor.shape[0]\n",
        "\n",
        "  reset_model = Net()\n",
        "  reset_state_dict = reset_parameters(trained_model.cpu(), informative_params)\n",
        "  reset_model.load_state_dict(reset_state_dict)\n",
        "  reset_model.to(DEVICE)\n",
        "\n",
        "  unlearn_model = UnlearnNet(reset_model, informative_params)\n",
        "\n",
        "  print(\"Unlearn model parameters:\")\n",
        "  for name , param in unlearn_model.named_parameters():\n",
        "      print(name, param.shape)\n",
        "\n",
        "  unlearned_model_finetuned = adam_trainer(unlearn_model, criterion, retain_loader, epochs=1)\n",
        "\n",
        "  acc_forget, _ = validate(reset_model, forget_loader, n_classes, DEVICE)\n",
        "  acc_retain, _ = validate(reset_model, retain_loader, n_classes, DEVICE)\n",
        "  acc_test, _ = validate(reset_model, test_dl, n_classes, DEVICE)\n",
        "\n",
        "  acc_forget_relearned, _ = validate(unlearned_model_finetuned, forget_loader, n_classes, DEVICE)\n",
        "  acc_retain_relearned, _ = validate(unlearned_model_finetuned, retain_loader, n_classes, DEVICE)\n",
        "  acc_test_relearned, _ = validate(unlearned_model_finetuned, test_dl, n_classes, DEVICE)\n",
        "\n",
        "  result = {\n",
        "      \"Unlearning %\": f\"{unlearning_percentage}%\",\n",
        "      \"Forget Set Acc\": f\"{acc_forget.item():.4f}\",\n",
        "      \"Retain Set Acc\": f\"{acc_retain.item():.4f}\",\n",
        "      \"Test Set Acc\": f\"{acc_test.item():.4f}\",\n",
        "      \"Forget Set Acc Relearning\": f\"{acc_forget_relearned.item():.4f}\",\n",
        "      \"Retain Set Acc Relearning\": f\"{acc_retain_relearned.item():.4f}\",\n",
        "      \"Test Set Acc Relearning\": f\"{acc_test_relearned.item():.4f}\",\n",
        "      \"Reset Params\": total_individual_reset_params\n",
        "  }\n",
        "  return result"
      ],
      "metadata": {
        "id": "maAC9ApF0tDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentages_to_test = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "all_results = [baseline_results]\n",
        "\n",
        "print(\"\\n--- Starting Unlearning Evaluation Loop ---\")\n",
        "\n",
        "for p in percentages_to_test:\n",
        "    print(f\"Running test for {p}% unlearning...\")\n",
        "\n",
        "    test_params = {\n",
        "        'unlearning_method': \"information\",\n",
        "        'unlearning_percentage': p,\n",
        "        'whitelist': None,\n",
        "        'blacklist': None\n",
        "    }\n",
        "\n",
        "    current_result = run_tests(test_params, trained_model, n_inputs, n_classes, DEVICE)\n",
        "    all_results.append(current_result)\n",
        "\n",
        "print(\"\\n--- Evaluation Complete ---\")\n",
        "\n",
        "results_df = pd.DataFrame(all_results)\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "o-HK2Q6hHLgE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}